# System Investigation Report

**Date**: 2025-07-07  
**Investigation Type**: Technical Architecture Review  
State of the Art Report
Track A: Product & UX Benchmarking
Leading Apps for Profile, Wallet & Notifications (2023–25): Top travel and fintech apps have raised the bar for user profiles. Airbnb exemplifies profile completeness and trust – it nudges users to verify ID, add a profile photo, and complete personal details for a “Complete” profile, enhancing trust in the marketplace. LinkedIn pioneered gamified profile completion with its “All-Star” meter, which increases as users add recommended sections (photo, location, skills, etc.). In travel, Expedia and TripIt encourage storing traveler info (passports, TSA PreCheck numbers) to speed up bookings. Cathay Pacific’s member portal allows saving multiple passports (for the user and up to 3 travel companions) and highlights that this “save[s] time during online booking and check-in”. Kayak and Google Flights focus on seamless wallet integration and notifications: Kayak’s user accounts can store payment methods for one-click bookings, and both offer granular price alerts. Fintech apps like PayPal and Revolut set standards for integrated wallets – allowing users to store cards, bank accounts, even crypto, with easy management and security controls (biometric lock, 2FA). These apps make adding a payment method feel secure and beneficial, often via on-screen cues that card info is encrypted and easily removable. Google Wallet/Pay integration is common in top apps, letting users import cards or use saved payment credentials for faster checkout.
UI Patterns Driving Profile Completion: Gamification and progressive disclosure are key. Progress Bars & Meters: Many apps use a profile progress bar or “completion percentage” to motivate users. Seeing a meter approach 100% triggers completionist instincts. For example, LinkedIn’s meter moves users from Beginner to All-Star status, with prompts on how to reach the next level. Checklists & Next-Best-Action Nudges: Apps present missing profile info as a checklist of tasks – e.g. “Add your phone number (worth 10%)” or “Upload a profile photo to reach 80%.” This provides clear next steps. Some travel apps show a “Profile completeness widget” on the account screen with 2–3 suggested actions (like “Verify your email for bonus points”). Reward & Feedback Loops: Gamified systems may reward completion with badges or perks (Airbnb sometimes labels fully verified profiles as “Trusted” which can improve booking success). In-context prompts: Instead of forcing a long sign-up form, best-in-class apps use contextual prompts during usage. For instance, when a user starts a booking and hasn’t saved traveler details, the UI might say “Save your passport to profile to autofill next time” – offering a one-click add. This progressive profiling approach collects data gradually when relevant. Visual cues like green checkmarks for completed sections and encouraging copy (“Nice! Your profile is 70% complete”) make the process feel like an achievement rather than a chore.
Justifying Data Collection & Building Trust: Leading apps are transparent about why they ask for personal data. They employ friendly UX copy to alleviate privacy fears. For example, when requesting passport details, an app might explain: “We use this to auto-fill your bookings and save you time. Your data is encrypted and only shared with airlines when you book.” Framing the benefit (saved time, personalized service) and reassurance (data protection) is critical. Privacy copy is often displayed next to sensitive fields (e.g. a tooltip “Your phone number is only used for verification and important alerts”). Apps also give users control – making fields optional if possible, or providing skip options. A best practice is acknowledging sensitivity directly. For instance, “We know your ID is sensitive. We’ll keep it secure and only use it to verify your identity – never for anything else.” This upfront honesty builds trust. Autofill & convenience messaging: Fintech apps justify linking bank accounts by highlighting convenience (“Link your bank to enable instant transfers”) and security (“Powered by secure bank APIs”). Travel apps like Skyscanner and Kayak justify enabling location access or notification permissions by explaining the user benefit (e.g. “Enable notifications to get instant price drop alerts”). They also allow granular control, which implicitly increases trust – users see they can toggle off marketing emails or set quiet times. In summary, gold-standard apps treat personal data as an exchange: they clearly communicate the value to the user and the safeguards in place, leading to higher profile completion rates.
Track B: Engineering Architecture
API Versioning on Supabase Edge Functions: Supabase Edge Functions (running on Deno) by default expose endpoints under a versioned path (e.g. /functions/v1/...), but there’s no built-in mechanism to deploy multiple API versions concurrently. Best practice is to implement explicit versioning in your function naming or routing. For example, you might deploy separate functions like secure-traveler-profiles-v2 while legacy clients continue using ...v1. This approach isolates changes per version. A community recommendation is to include a router inside a single function to handle version param in the request, but that adds complexity and is less clear. Instead, prefer separate endpoints per major version, which aligns with general API versioning best practices (making the system more maintainable and changeable). Supabase’s URL structure already includes /v1/ (for their own versioning), so our versioning would be at the function name level. We should document deprecation of v1 once v2 is stable. In summary, incremental version releases (v1, v2, etc. as separate functions or paths) will allow us to evolve the API without breaking existing apps – a necessity for a robust platform.
Twilio Verify: Webhook vs Client Callback Trade-offs: Parker Flight currently sends verification codes via Twilio (SMS) through an Edge Function and then the frontend verifies the code by calling a backend function (a client-driven verification check). Twilio offers a Verify API that can handle OTP generation, sending, and validation, with optional webhooks for status. The trade-offs come down to control vs convenience. Using Twilio Verify with Webhooks: Twilio would send a webhook to our backend when a verification attempt succeeds or fails, letting our system react in real-time (e.g. unlock features as soon as the phone is verified) without the client polling. This decouples the verification outcome from the client flow. It’s great for audit logging and for handling cases where verification might be done outside the app (e.g. via a code in SMS reply). However, it requires exposing a public endpoint and handling Twilio’s signed requests. On the other hand, Client-Callback Verification (the current approach) means the app itself (or our function) calls Twilio’s Verify Check API when the user enters the code, and Twilio returns success/failure instantly. This is simpler in a linear user flow and keeps the verification logic self-contained. Security & Fraud: Twilio’s Verify service brings added anti-fraud measures. It only charges on successful verifications and has built-in protections like rate limiting to prevent SMS pumping attacks. A custom solution would need us to build these checks. Twilio also manages global sender routing and regulations (10DLC in the US, etc.), whereas a DIY approach means handling phone number logistics. Cost: Twilio Verify costs about $0.05 per verification plus SMS fees. Simply sending SMS ourselves is cheaper per message, but we’d miss the fraud prevention and have to maintain code generation and expiration logic. Many teams find that the development and maintenance effort of a custom 2FA/verification system, plus dealing with edge cases, ends up costing more in the long run. Recommendation: Use Twilio Verify’s API for phone verification, with server-side verification checks (no need for webhooks unless we require asynchronous handling). This approach provides the best balance – we leverage Twilio’s secure code generation and validation by calling their verify check from our backend when the user submits the code. It ensures one-time codes aren’t kept in our database and offloads heavy lifting to Twilio. We can log verification events via Twilio’s Verify Events webhook for analytics (e.g. track how many attempts users needed), but primary flow can remain client-driven. This keeps the UX simple (instant feedback) and the implementation secure. In future, if we adopt alternate channels (WhatsApp, voice call), Twilio Verify will allow us to integrate those easily.
Stripe: Deleting Cards & Customer Data Cleanup: Properly handling payment method removal is crucial for security and compliance. Stripe PaymentMethods Detach: In Stripe’s latest API, saved cards (PaymentMethod objects) attached to a Customer can be detached using the Stripe API. Detaching a card removes it from the customer while keeping a record in Stripe (for audit, etc.), and if it was the default payment source, Stripe will automatically adjust the default to another card if available. Our implementation should call stripe.paymentMethods.detach('pm_xxx') when a user deletes a card, and then also remove the reference in our payment_methods table. We saw in the current UI an emphasis that deleting a payment method “will remove it from both our system and Stripe”, which is correct. We just need to ensure we do not leave orphaned Stripe Customers or PaymentMethods. Deleting Customer Objects: Best practice is generally not to delete a Stripe Customer record unless absolutely necessary. Other systems advise against it because past invoices, subscriptions, or records could be needed later. If a user fully deletes their Parker account and requests data removal (GDPR), Stripe provides a way to redact personal data instead of outright deletion. We should use Stripe’s redaction process for full deletions: cancel any pending payments (PaymentIntents), detach all payment methods, then delete the customer or invoke Stripe’s GDPR deletion which redacts personal info. For routine card removals, do not delete the whole Customer – just detach the card. This preserves the customer ID for future use (so if the user adds a new card later, we don’t create duplicate customer records needlessly). Additionally, ensure we handle default card logic: if the user removes their default card, our UI/backend should let them choose a new default (Stripe automatically picks one, but we should surface that choice). We also need to heed Stripe’s security webhooks: if using Stripe Checkout or SetupIntents, a card may be saved via a token – upon deletion we should also revoke any associated mandates or subscriptions (if we had any recurring payments, which in our case might not apply). In short, the proper method is: call Stripe’s detach API for the card, confirm it’s removed (Stripe returns a confirmation), delete our local record, and log the action. If the user is deleting their account, detach all cards then delete the customer via stripe.customers.del() or use Stripe’s Data Retention tools, mindful of waiting periods (Stripe may require no pending transactions within last 90 days for full deletion for fraud reasons).
LaunchDarkly vs Split vs In-House Feature Flags: Parker’s tech stack already includes LaunchDarkly, a leading feature flag platform, so the decision is whether to continue with it or consider alternatives. LaunchDarkly offers a robust, enterprise-grade feature management system with fine-grained user targeting, a slick UI for non-developers to toggle features, and an edge network for low-latency flag evaluation. It can evaluate flags in <200ms via its CDN globally, and supports unlimited custom user attributes for targeting (e.g. enable a feature for beta testers or by region). Split is another strong platform, with an added focus on A/B testing and experimentation. It allows statistically measuring the impact of feature toggles (e.g. how a new feature affects conversion), which is valuable if we plan to run experiments. However, Split was acquired by Harness in 2024 and is similarly positioned for enterprise – it might be overkill if we are not actively doing multivariate testing. A noted limitation: Split supports a single “context” type per flag (commonly just user), whereas LaunchDarkly allows multiple context kinds (user, account, etc.) per flag for more flexibility. In-house (DIY) flags: Building a simple feature flag system (e.g. a table in Supabase with flag keys and boolean states) is feasible for basic on/off toggles, but comes with high operational cost. As developers on forums have noted, the bulk of cost in feature flagging isn’t building the toggle but maintaining it reliably at scale. An in-house solution would require ensuring low latency (possibly setting up our own CDN or edge logic for flags), fail-safes (so flags don’t flicker or go down and break the app), and a UI or process for non-engineers to use it. LaunchDarkly and Split handle these concerns out of the box, with redundancy and analytics. Cost considerations: LaunchDarkly can be expensive as we scale (pricing is usually by MAUs or seats and can reach tens of thousands per year for large user bases). Split’s pricing is similar. If cost becomes prohibitive, there are open-source alternatives like Unleash or Flagsmith which we could self-host, but that shifts burden to us to manage uptime and updates. In a recent discussion, engineers mentioned companies often move off DIY to managed flags because it’s cheaper to focus on core business than reinvent feature flag infrastructure. Recommendation: Continue with LaunchDarkly for now, given it’s already integrated and provides the targeting power and developer experience we need. Its real-time updates and multi-environment support will be valuable for progressive rollouts. We should leverage LaunchDarkly’s segment targeting to gradually roll out new profile features (e.g. test the new profile UI with internal users first). We will keep an eye on seats/cost; if usage grows, an alternative could be to migrate to an open-source solution or a cheaper managed service, but that entails significant migration effort. Split does not offer a compelling advantage for our use-case (we are not heavily experiment-driven yet), so switching to it would introduce migration cost without clear ROI. Lastly, an in-house system is not recommended due to maintenance and reliability risks – feature flags are critical infrastructure, and a failure in flag service could, for example, disable key functionality in production, so we prefer a battle-tested platform.
Snowplow vs Segment for Event Tracking (“profile_score_updated”): The team wants to track profile completion events in an analytics pipeline, potentially to trigger real-time personalization (e.g. congratulate user on reaching 100% profile, or feed into a data warehouse for analysis). Segment is a SaaS customer data platform that excels at routing events from our app to many destinations (analytics tools, databases, marketing platforms). It’s essentially a managed pipeline with pre-built integrations. Its model is often “warehouse-first” for our use case – we could configure Segment to batch-send events like profile_score_updated to our data warehouse (Snowflake/BigQuery) for later analysis. However, real-time usage of events in Segment is limited by its processing times and pricing tier. Segment can forward events nearly in real-time to certain endpoints, but their warehouse syncs often run on schedules (e.g. every few hours, depending on plan). Snowplow is an open-source event pipeline where we have full control. It can be set up to stream events in real-time (e.g. via Kafka/Kinesis + real-time consumers) into our storage. According to Snowplow, it can deliver event data to your storage in as little as 5 seconds, enabling instant analytics or triggers (like showing a personalized recommendation immediately after an event). Segment, in contrast, typically cannot achieve such low latency to a warehouse or custom store – it’s more oriented toward convenience and breadth of integrations. Data Ownership & Schema: Snowplow’s approach requires us to define schemas for events (ensuring high data quality – events that don’t match schema are rejected). This is great for maintaining data integrity over time. Segment is more schema-flexible (it will send whatever payloads, which can lead to messy data unless carefully managed). Privacy & Control: With Snowplow, we self-host the pipeline (or use Snowplow’s managed service in our cloud) – all data stays under our controlsnowplow.io. Segment is a third-party SaaS that receives our user event data on their servers, which can raise compliance questions and lock-in concernssnowplow.io. Ease of Integration: Segment wins on ease – just drop in their SDK and call analytics.track("profile_score_updated", {...}), and it handles the rest, including retries, user identity resolution, etc. Snowplow requires deploying trackers (they have a JavaScript and Kotlin/Swift trackers we can use in our app) and running collector and enrichment services. It’s more engineering effort upfront. Use case consideration: If our profile_score_updated event is primarily for internal analytics (feeding a dashboard or machine learning model later) and not needed for real-time user feedback, Segment’s warehouse approach could suffice. But if we envision real-time reactions – for example, instantly tailoring the home screen when a user’s profile hits 100%, or sending a “Profile Complete!” email immediately – Snowplow is better suited. It supports real-time streams that we could plug into a consumer to trigger such actions. Also, Snowplow avoids vendor lock-in: we can pipe data directly to PostgreSQL or wherever and join with our production data. Recommendation: For future-proofing and real-time needs, Snowplow is the choice. It provides a first-party data pipeline under our control, with real-time capability that Segment lacks at low latency. We will need to allocate effort to set it up, possibly using Snowplow’s managed SaaS or an open-source deployment on AWS. If ease and speed of implementation is a priority and we don’t need real-time, we might start with Segment for quick wins (it’s certainly faster to implement initially). But given 2025 trends of owning your customer data and avoiding third-party dependencies, Snowplow aligns with our long-term vision. Notably, Snowplow data can still be sent to a warehouse but in a streaming fashion, and we can enforce a strict schema for profile_score_updated events (containing user_id, old_score, new_score, etc.) to guarantee high quality data. We will design our event tracking to be Snowplow-compatible from the start (using their tracker libraries), even if we temporarily also pipe events into Segment for other integrations. This ensures we’re ready for real-time personalization use cases in 2025–26.
Track C: Future-Proofing
Multi-Traveler Profile Support & Group Bookings: Our schema and UI need to evolve beyond the one-user-one-profile model. Currently, a Parker user likely has one primary traveler profile (their own). To support families or travel planners (assistants, corporate travel managers), we want to allow multiple saved travelers per account. The database is already hinting at this – our traveler_profiles table has a user_id and can be one-to-many, but the front-end and API currently assume one active profile. We should extend the UI to manage multiple Traveler entries. UI schema: Introduce a “Travelers” subsection in the profile area where a user can “Add New Traveler”. This would include form fields for name, DOB, gender, passport info, etc., and possibly a label (e.g. “Myself”, “Spouse”, “Child 1”). Users can then pick a traveler when booking or share profiles in group bookings. For group bookings: if a user searches for 4 tickets, the booking flow can let them select which saved travelers to assign to those seats. We should ensure the traveler profiles include all necessary fields (e.g. passport number, known traveler number, meal preferences) to auto-fill booking forms. Data model: The traveler_profiles table will use user_id as foreign key for the owner. We might add a relationship field (“self”, “child”, etc.) or let users simply name the profile. Ensuring quick selection is key – best practice is showing a dropdown of saved travelers during checkout. Cathay Pacific already allows up to three companion documents saved for easier group management, which validates our approach. For true group bookings (where multiple people’s itineraries are linked), we might later support linking multiple Parker accounts into a booking, but initially focusing on one account managing multiple travelers covers most scenarios (e.g. a parent booking for kids). This multi-traveler support is not only a UX enhancement but also a retention feature – if Parker becomes the repository of all your family’s travel docs, you’re likely to continue using it.
Omnichannel Notifications, Quiet Hours & Digests: Modern users expect control over when and how they receive notifications. We plan to implement an omnichannel notification preference system that goes beyond the current binary email/SMS toggles. Quiet Hours: Users should be able to define a daily time window during which notifications are suppressed or queued. For example, a user could set quiet hours from 10:00 PM to 7:00 AM – during that period, urgent transactional alerts (like a flight cancellation) might still be sent, but less critical alerts (price drops, marketing) would be held or sent as a summary later. Apps like Microsoft Teams and Slack allow setting such do-not-disturb schedules. We would add UI in the Notifications settings: e.g. a time picker for “Do not send push/SMS between __ and __”. Our notification sending logic (likely in the backend job or via third-party service) must check user preferences and either delay those notifications or switch to a silent mode (maybe send to an email digest instead of SMS during quiet hours). Digest Frequency: For non-urgent updates like promotional offers or perhaps daily price alerts, let users choose a digest instead of immediate pings. For instance, a user could opt to receive “daily digest at 8 AM” for price alerts instead of real-time. Kayak’s alerts UI, for example, allows adjusting frequency – users can get daily emails rather than every single price change. Momondo actually limits alert emails to two per week by default, to avoid spamminggoing.com. We should provide options such as immediate vs. daily vs. weekly summary for certain categories of notifications (especially marketing or price tracking). Channel Preferences: Currently, we have checkboxes for Email and SMS per notification type. In future, we might add Push notifications (if Parker Flight has a mobile app or web push). Our system should be extensible to add channels. Using a JSONB notification_preferences field is good (already implemented) – we can extend it with fields like quiet_hours and digest_frequency. The UI can remain similar but with additional controls grouped under “Delivery Preferences”. Implementation note: We’ll likely need a scheduler (could be a CRON in Supabase Edge Functions or an external worker) to actually send digests at the chosen times. Also, any immediate notifications system (like Twilio SMS or Resend emails) must check if the current time is within the user’s quiet period. We should also allow an override for urgent communications (e.g. booking failure might ignore quiet hours because the user needs to know). This can be handled by categorizing notifications by urgency. Overall, giving users these controls not only improves UX but also compliance (e.g. respecting user’s nighttime peace could reduce opt-outs). We’ll also include a global “Pause all non-essential notifications” toggle for vacation mode, which some apps provide.
Accessibility (WCAG 2.2 AA) & Localization (RTL, i18n): As we approach 2025–26, accessibility standards have advanced. We commit to meeting WCAG 2.2 AA guidelines, which include the new success criteria introduced in 2.2 (published Oct 2023). These include improvements for users with low vision, cognitive or mobility impairments. For example, focus indicators must be clearly visible (WCAG 2.4.11/2.4.12 – focus not obscured, and 2.4.13 – focus appearance with sufficient contrast) – we will ensure that when a user tabs through our forms (profile, payment), the focused field is not hidden by any fixed footer and has a thick outline meeting contrast requirementsw3.org. Target size (2.5.8): All clickable controls (buttons, toggles) should be at least 24px in size to aid users with limited dexterity. We’ll review our UI components from Shadcn/UI (which is built on Radix and Tailwind) to ensure they meet this – Radix is generally accessible, but we might need to tweak styling for larger click areas on checkboxes, etc. Redundant entry (3.3.7): We should avoid asking users to re-type information that could be auto-filled or remembered (e.g. if a user’s address is on file, don’t force re-entry – allow a selection). Our profile system already stores data, but this principle means things like phone number in both traveler profile and user profile should sync or at least only need entry once. Localization and RTL: Parker Flight should be ready to support multiple languages and right-to-left scripts. We’ll internationalize the frontend using a library (e.g. i18next or react-intl). All user-facing strings will be moved to translation files. We will test the UI in at least one RTL language, such as Arabic, to ensure layout flips correctly (e.g. our tabbed interface should reorder, padding/margins invert, etc., when dir="rtl" is set). Luckily, modern CSS (flexbox, grid) makes mirroring layouts easier, but we must check components like carousels or icons that might need adjustment (e.g. an arrow icon might need to flip direction in RTL context). We should also consider locale-specific formatting – dates, times (e.g. 24-hour vs 12-hour time for quiet hours setting), and numeric formats. Screen reader and keyboard support: Using Radix UI ensures many components have proper ARIA roles and keyboard navigation by default. We’ll audit using tools like Axe or Lighthouse Accessibility. For example, ensure that our tab list for Account/Traveler Info/Notifications is marked with role="tablist" and each tab with role="tab", and that arrow keys can move between tabs. Testing with WCAG 2.2: We’ll specifically test scenarios like: can a user complete their profile using only a keyboard? (Tab through all fields, use space/enter on toggles). Are all form inputs properly labeled (we’ll use visible labels or aria-labels)? Do color combinations (e.g. our progress bar, or text over background in dark mode) meet contrast ratio 4.5:1 for normal text? We will also ensure orientation and zoom support – the app should work in mobile screen readers and support at least 200% zoom without breaking layout (WCAG 1.4.10). By adhering to WCAG 2.2 AA, we not only future-proof against legal risks (accessibility lawsuits) but also make the app more usable for everyone. Parker Flight should also prepare for any additional requirements likely in WCAG 3.0 (still in draft), but focusing on 2.2 AA now covers known best practices up to 2025. Lastly, we’ll incorporate localization workflows so that adding a new language is straightforward – e.g. using a translation management service or JSON files. We’ll design the UI to accommodate longer text common in other languages (German tends to be longer, for instance) and to be flexible with user’s locale for things like calendar (start of week, etc.). All these steps ensure our profile system can serve a global audience accessibly and inclusively.

Gap Analysis Matrix
Below is a comparison of Parker Flight’s current implementation (from the provided developer docs and UI screenshots) versus best-practice benchmarks for each profile-related feature. We include an effort score (approx development effort) and impact score (user/business impact) for addressing each gap, using 🟢 (low), 🟡 (medium), 🔴 (high) for scoring.
Feature
Current Implementation (Parker Flight)
Best Practice (2025 Benchmark)
Effort
Impact
Profile Completeness UX
Basic progress indicator (e.g. “Profile 0% complete”) with a button to fill info. No gamified feedback beyond % bar. <br/>– Profile_completeness_score is computed in backend, but UI just shows a percentage. Recommendations exist in code (e.g. get_profile_recommendations() logic) but are not exposed in UI.
Gamified progress meter with stages (Beginner/Intermediate/All-Star). Visual progress bar and checklist of missing items. <br/>– Next-best-action prompts: e.g. “Add a phone number to reach 50%” beneath the meter. <br/>– Rewards/Feedback: e.g. confetti or badge when reaching 100%. <br/>– Contextual nudges on relevant screens (e.g. on wallet page, “Adding a card will boost profile completeness by 10%”).
🟡 Medium (UI dev & copywriting)
🟢 High (drives engagement)
Data Collection & Trust
Collects personal data (phone, passport, etc.) but with minimal explanatory text. Privacy policy exists but in settings footer. <br/>– Phone verification flow explains necessity somewhat (“verify to enable SMS”). <br/>– No in-form tooltips about why certain data is needed; some users may skip passport info as they don’t see an immediate need.
Transparent, user-centric copy accompanying sensitive fields. <br/>– Just-in-time prompts: ask for info at point of need (e.g. when booking international flight, prompt for passport with note “Save to profile for faster checkout”). <br/>– Security reassurance: e.g. lock icons or notes (“We encrypt and securely store this”) near inputs for SSN/passport. <br/>– Option to skip or provide later, reducing user drop-off. <br/>– Clear privacy policy snippet or link right at data collection points.
🟡 Medium (content design & minor UI)
🟡 High (builds trust, compliance)
Multi-Traveler Profiles
Schema supports one-to-many traveler profiles, but UI only exposes one profile (the user). No interface to add/manage additional travelers. <br/>– Bookings currently assume the user is the traveler (no selection of traveler profiles).
UI to manage multiple saved travelers (family, etc.). <br/>– Traveler list in profile section: “Add Traveler” form, listing of saved profiles with names. <br/>– Booking integration: ability to select which traveler(s) a booking is for, or add companions from saved profiles. <br/>– Data: store documents for each traveler (passports, known traveler #) and auto-fill during booking. <br/>– Possibly share traveler profiles across linked accounts (future).
🔴 High (backend + significant UI workflow)
🟢 High (expands user base, convenience)
Notification Preferences
Users can toggle Email/SMS for categories (booking confirmations, reminders, price alerts, etc.). Phone verification required for SMS toggles. <br/>– No support for scheduling or digest; notifications are immediate. <br/>– “Marketing” communications are lumped in one toggle.
Granular and user-friendly notification control. <br/>– Quiet hours setting to suppress alerts during specified times. <br/>– Digest options for low-priority alerts (e.g. “daily summary” instead of instant for price alerts). <br/>– Channel expansion: ability to enable Push or WhatsApp as alternatives. <br/>– Separate toggles for critical vs promotional alerts (already partly done). <br/>– UI hints if user tries to toggle SMS without phone verified (already does this with a note).
🔴 High (backend scheduler + UI changes)
🟢 High (user satisfaction, retention)
Wallet Integration & Payment
Integrates Stripe for saving cards. UI shows saved cards (if any) and allows deletion. <br/>– Currently supports basic credit/debit via Stripe. No integration with Apple/Google Pay or PayPal. <br/>– Deletion currently only on our side? (Planned to remove from Stripe too per guide, but needs verification). <br/>– No explicit “set default” card UI (though Stripe auto-defaults the first).
Comprehensive wallet experience. <br/>– Multi-method support: allow storing multiple cards, bank accounts, etc., and mark one as default for bookings. <br/>– One-click add via Apple Pay/Google Pay integration (use Payment Request API or Stripe’s SDK to save those tokens). <br/>– When deleting a card, ensure backend detaches it from Stripe and confirms removal in UI (maybe an undo option). <br/>– Security: show last4 and card brand logo, but not full info (current UI likely does this). Possibly require re-auth (e.g. re-enter password) to add/delete a payment method for security. <br/>– If user deletes all payment methods, consider deleting Stripe customer after a grace period (or anonymizing) for GDPR.
🟡 Medium (Stripe API usage & front-end tweaks)
🟡 Medium (streamlined bookings, trust)
Phone Verification Flow
Uses Twilio SMS via Supabase function. User enters code in frontend, which calls backend to verify (custom logic). <br/>– Relies on our implementation for code generation/validation (potentially using Supabase DB or in-memory). <br/>– Basic error handling (invalid or expired codes) in place, but no advanced fraud detection beyond rate limiting via frontend.
Use Twilio Verify API for robust OTP handling. <br/>– Offload code management to Twilio: our backend calls Verify.v2 to send OTP, and calls Verify check for validation, rather than rolling our own codes. Twilio’s service handles global sender routing and only charges on successful verifications, plus prevents abuse (SMS pumping). <br/>– Optionally implement Twilio’s webhook events for verification attempts: could log when codes are sent, and if an OTP was attempted incorrectly multiple times (for security audit). <br/>– UX improvements: show a countdown timer and “resend code” option (with Twilio Verify, subsequent attempts are throttled by Twilio). Use Twilio’s supported localizations for SMS templates to send codes in user’s language (if applicable). <br/>– Keep the overall flow user-driven (enter code -> instant feedback) to maintain a smooth UX.
🟡 Medium (integrating a new API, testing)
🟡 Medium (security, success rate)
API Versioning & Modularity
Single version of Supabase Edge Function (secure-traveler-profiles) serving all profile operations. No explicit versioning scheme for API endpoints – clients and backend use the same function. <br/>– “v1” appears in URL (supabase proxy) but it’s not tied to our own versioning. <br/>– Future changes risk breaking compatibility without a version strategy.
Robust versioning strategy for APIs. <br/>– Separate endpoints per version: e.g. deploy a v2 function for profile API when introducing breaking changes. Clients include /functions/v1/secure-traveler-profiles-v2 in URL or similar. Alternatively, embed version in request payload and route internally, but splitting functions is cleaner. <br/>– Ensure backward compatibility during transition: maintain v1 until majority of users migrate to app version supporting v2. <br/>– Documentation for each version (API contract differences). <br/>– Consider using a lightweight router in the Edge Function to direct based on URL path segments if we prefer a single function deployment – though not necessary for our scale. <br/>– Overall, treat the Edge Function like versioned REST endpoints, aligning with best practices in API design (versioning is crucial for changeable software).
🟢 Low (naming convention and minor code mods)
🟡 Medium (reduces future tech debt)
Feature Flagging
Using LaunchDarkly for feature toggles (implied by stack). Likely a few flags in use (e.g. to hide incomplete features). <br/>– Probably using client-side SDK or evaluating flags in Edge Functions for SSR. <br/>– Not a lot of complexity yet, but cost grows as usage grows (LaunchDarkly pricing). <br/>– No in-house override system; dependent on LD service uptime.
Modern feature management with cost-awareness. <br/>– Continue with LaunchDarkly for its robust targeting and rollout capabilities – it’s industry-leading and avoids us reinventing the wheel. It provides global low-latency flag delivery via CDN and a user-friendly UI for product to manage flags. <br/>– Periodically review flag usage and cleanup unused flags (to control LD costs and complexity). <br/>– If costs become an issue, evaluate open-source alternatives (e.g. Unleash, Flagsmith) – but note that self-hosting has hidden costs and reliability concerns. <br/>– For now, use LD’s advanced features: e.g. experiment with percentage rollouts (progressive release of profile revamp to 5%, 50%, 100% users), and context-based targeting (maybe enable certain features for power users or specific cohorts first). <br/>– Document fallback behaviors in case LD is down (the app should have safe defaults if flag fetch fails, perhaps cached flags).
🟢 Low (already integrated; just policy changes)
🟡 Medium (ensures safe rollout of new features)
Analytics & Event Tracking
Minimal explicit event tracking. Profile changes are logged in DB (profile_completion_tracking table) but not propagated to any analytics service in real-time. <br/>– No Segment or Snowplow in use yet; likely relying on Supabase logs or simple Google Analytics for basic usage stats. <br/>– Lacks visibility into user behavior like where drop-offs happen in profile funnel.
Instrumentation of key events with a modern analytics pipeline. <br/>– Profile funnel events: send ProfileStarted, ProfileSectionCompleted, ProfileCompleted events to an analytics system. Use these to analyze where users drop off (e.g. many users add name/email but stop at phone verification – that insight helps improve UX). <br/>– Segment integration for quick routing to multiple tools (Amplitude for product analytics, marketing automation for triggered emails on completion, etc.), or Snowplow for a self-owned data pipeline with real-time streaming. <br/>– Given our real-time needs (like showing a celebratory message upon completion), implement Snowplow for instantaneous event capture – it can deliver events to our warehouse in seconds for AI personalization or trigger functions. <br/>– Ensure events have rich context (user id, plan type, etc.) and use a schema to maintain quality. <br/>– Leverage analytics to A/B test improvements: e.g. does adding a profile progress bar increase completion rate? These systems will provide the data to answer that.
🟡 Medium (SDK integration + infra for Snowplow)
🟢 High (data-driven decisions, personalization)
Accessibility & i18n
Basic compliance with WCAG 2.1 in UI components (due to using Radix UI library). <br/>– Not tested yet for WCAG 2.2 specifics. <br/>– No localization; English only. Some components may not be RTL-aware (e.g. the progress bar and form layout likely not tested in RTL). <br/>– Color scheme is light/dark but need to verify contrast ratios.
Fully accessible and localized interface. <br/>– WCAG 2.2 AA: meet new criteria (e.g. focus states are always visible and clearw3.org, pointer target size >= 24px, no unexpected context changes). Perform accessibility audit with tools and real users. <br/>– Keyboard navigation: ensure all interactive elements (tabs, toggles, sliders for quiet hours) are operable via keyboard with visible focus. <br/>– ARIA labels for custom components (e.g. our progress circle should announce “Profile 50% complete”). <br/>– Localization: externalize all strings, use a i18n framework. Prepare at least one additional language (maybe Spanish) to test. <br/>– RTL support: use CSS logical properties or conditional class for RTL to flip layouts. Test Hebrew/Arabic – the profile form should still read intuitively right-to-left, and components like progress text should adjust (e.g. percent symbol positioning). <br/>– Testing: Include users with screen readers in beta testing, and use unit tests for things like color contrast (some design systems have automated tests for this). <br/>– Complying now positions Parker Flight well for regulatory compliance (e.g. European Accessibility Act by 2025) and broadens our user reach.
🟡 Medium (mostly front-end tweaks and testing)
🟡 Medium (avoid legal risk, improve UX)

※ Effort/Impact Legend: Effort: 🟢 Low (small change), 🟡 Medium (moderate dev work), 🔴 High (significant project). Impact: 🟢 High (major positive impact), 🟡 Medium, 🔴 Low (minor improvement).

Recommended Architecture & Library Choices
After evaluating the options in each area, we propose the following final decisions for Parker Flight’s architecture upgrades, along with rationale and migration notes:
1. Supabase Edge Function API Versioning – Use URL-Versioned Functions: We will adopt an explicit versioning scheme by deploying separate Edge Functions for each API version (e.g. secure-traveler-profiles-v2). Rationale: This approach isolates changes cleanly – we can iterate on v2 without affecting v1 consumers. It aligns with REST best practices of explicit versioning, which is important for maintainability. Alternative (routing internally based on a parameter) was considered but adds unnecessary complexity in our case. Migration: The current function (v1) remains live. We create secure-traveler-profiles-v2 with the new request/response format (if changes are needed). We update the front-end (and any API clients) to call the v2 endpoint. Both versions run in parallel during a transition period. We monitor logs for any v1 usage and, once negligible, decommission v1. We’ll document differences in our API docs. Going forward, any breaking change triggers a new version deployment. Non-breaking updates (adding optional fields, etc.) can occur within the same version. This strategy ensures we can evolve the profile API (e.g. to support multi-traveler data structure) without sudden breaks.
2. Phone Verification – Implement Twilio Verify (Server-side Checks, Optional Webhooks): We choose to integrate Twilio’s Verify API for SMS-based phone verification, replacing our custom OTP logic. Rationale: This leverages Twilio’s scalable, secure OTP service – reducing our code to maintain and benefiting from deliverability optimizations and fraud protections (like auto-expiring codes, preventing brute force). Twilio Verify also simplifies going multi-channel in future (supporting WhatsApp, voice calls, or email OTP through the same API). Architecture: When a user enters a phone to verify, our backend will call Twilio.verify.v2.services(...).verifications.create to send the code. We will no longer generate or store codes in our DB. When the user inputs the code, our frontend calls our backend function which in turn calls ...verifications.check via Twilio’s API. If valid, we mark phone_verified=true in our profile DB. Webhooks: We will enable Twilio Verify’s status webhook for analytics – Twilio can ping an endpoint of ours on verification attempt success or failure. This is not required for the core flow, but gives us real-time events (we can log how many attempts a user needed, etc., or trigger a welcome SMS via Twilio’s post-verification webhook). Migration: Minimal impact on UX – user flow remains “enter code, get feedback”. We need to test the new flow thoroughly (Twilio’s sandbox and test phone numbers help here). We must also update .env with Twilio Verify Service SID. Our current Twilio integration (.ts library and env vars) can be repurposed or simplified since we won’t manually manage codes. Cost-wise, each verification is slightly higher cost than plain SMS, but given the improved success rates and security, it’s justified. We will monitor usage to ensure it stays within budget. We’ll remove the old code verification storage from our DB (if any) and clearly handle errors (e.g. expired code – the API returns specific error codes we can surface to the user). The Twilio Verify integration will be done in Sprint 2.
3. Stripe Payment Method Cleanup – Detach Card then Conditional Customer Deletion: For managing saved cards, we will use Stripe’s recommended approach: detach PaymentMethods instead of deleting Customer objects. Rationale: Detaching a card (stripe.paymentMethods.detach) removes the card from the customer while keeping the customer record intact. This ensures any future additions use the same customer, preserving history (useful for analytics and potential future subscriptions) and avoids issues with invoice records. We only consider deleting the Customer entirely upon full user account deletion (and even then, Stripe suggests data redaction rather than full deletion in some cases). Implementation: When a user deletes a card via the UI, our backend will call Stripe to detach it. We will also update our payment_methods table to remove it. We’ll implement logic to check: if that card was the default, we’ll mark another card as default both in Stripe (Stripe auto-selects another default source) and in our DB. We’ll expose a “Set as default” action in the UI for clarity. Customer deletion: If a user deletes their Parker Flight account, our offboarding process will: cancel any pending transactions, detach all cards, then call stripe.customers.del() to delete the customer. According to Stripe, this deletion is soft in that personal data is wiped but some record may remain for compliance. We will use Stripe’s bulk data removal tool if needed to satisfy GDPR requests. Migration: We confirm that currently saved payment methods in Stripe have corresponding DB entries; if any drift, we’ll reconcile. We test deleting a card flow end-to-end (ensuring the card no longer shows up and Stripe’s dashboard reflects removal). If any existing code was simply deleting our DB record, we replace that with the Stripe detach call. We update user messaging: on deleting a card, show a success message like “Card removed. You will need to add a new payment method for future bookings.” (or if no cards left, maybe prompt to add one). Also document for support that if a user wants their data fully expunged, support can use Stripe’s redaction (since direct Stripe API deletion might be limited if there are recent charges, but for Parker Flight’s use-case, charges are on demand). Overall this choice ensures compliance and consistency with Stripe’s best practices while giving users control over their wallet.
4. Feature Flags – Stick with LaunchDarkly (Monitor Cost, Leverage Advanced Targeting): We decide to continue using LaunchDarkly as our feature flag solution, rather than migrating to Split or building in-house. Rationale: LaunchDarkly is already integrated and provides a proven, developer-friendly platform. It offers superior flexibility (multiple context types, rich rules) compared to Split, and we currently do not need Split’s heavy experimentation focus. In-house feature flag systems were ruled out due to high maintenance and reliability risks – flags are critical and we prefer not to risk downtime or stale flags due to a custom system. Cost & DX: We will optimize our usage of LaunchDarkly to control cost: using its client-side evaluation where appropriate (LaunchDarkly’s React SDK) to avoid unnecessary network calls, and archiving flags that are no longer in use (since LD charges by active flags and seats). We will also enforce an internal policy that every flag should have a “cleanup date” – ensuring we don’t accumulate technical debt. Migration: No migration needed since we’re not switching providers. However, we will upgrade to the latest LaunchDarkly SDK version and verify that we are using secure mode (so that user identities are hashed server-side if we identify users in flags). We will also integrate LaunchDarkly with our monitoring – e.g., if a flag rollout is misbehaving, we get alerts (LaunchDarkly has a Slack integration for flag changes which we’ll enable to track when flags are toggled). Advanced usage: We plan to use LaunchDarkly’s variation targeting to release the new profile features gradually. For example, create a flag profile.revamp.enabled and target a small % of random users or internal users first. Also use their context to perhaps target new sign-ups differently from long-time users (if needed). LaunchDarkly’s edge network ensures flag changes propagate instantly to users, which is great for kill-switches if something goes wrong. By doubling down on LaunchDarkly, we capitalize on a stable feature management practice and avoid derailing the project with a complex migration. We will revisit this decision in a year; if our user count skyrockets making LaunchDarkly cost-prohibitive, we might evaluate more economical options like Flagsmith (open-source), but that would be a separate project.
5. Event Tracking – Implement Snowplow for Real-Time Analytics (Augment with Segment if needed): We will deploy a Snowplow Micro pipeline for our product analytics, focusing on events like profile completion, and keep Segment as an optional add-on for marketing integrations. Rationale: Snowplow gives us ownership of event data and the ability to react in real-time. For example, when a user’s profile_completeness_score crosses a threshold, we could trigger a personalized in-app message within seconds – Snowplow can stream an event to a consumer that our app listens to. Segment alone cannot guarantee that low latency; it is more geared toward funneling data to warehouses or third-party tools on a schedule. Additionally, Snowplow’s enforceable schema approach will maintain data integrity as we scale analytics – we define the event structure and Snowplow will reject bad data, preventing garbage-in. Architecture: We’ll run the Snowplow collector and enrich pipeline (possibly using their managed service or a lightweight setup) and configure it to output events to our data warehouse (Postgres or BigQuery). We’ll use Snowplow’s JavaScript tracker in our React app to emit events like profile_score_updated (with properties like old_score, new_score, sections_completed). We’ll also send events from our backend (e.g. when a booking is made) using Snowplow’s Node.js tracker. For any real-time triggers, we can use Snowplow’s real-time stream (Kinesis or PubSub) to feed a small Node service that listens for specific events (like profile 100% event) and then calls our notification system to, say, send a “Congrats on completing profile” email via Resend. Meanwhile, we still recognize Segment’s strength in easily connecting to external services (e.g., if marketing wants to pipe events to Google Analytics or a CRM). We may use Segment as a downstream consumer of Snowplow data or dual-send critical events to both systems. But to avoid duplication, the primary source will be Snowplow feeding our warehouse for analysis and AI modeling. Migration/Implementation: Since currently we have no complex event system, we start fresh. We’ll allocate time to set up Snowplow – possibly using their quickstart which can deploy to our cloud in a day or two. We ensure compliance (update our privacy policy that we collect behavioral events, since we own that data). For developers, we’ll provide a wrapper function to track events to Snowplow easily. We also plan out our event taxonomy upfront – list what events we’ll track and their schema – to avoid chaos later. E.g. define ProfileScoreUpdated event schema (userId, oldScore, newScore, changedFields list, timestamp). This schema will be registered in Snowplow. We then instrument the front-end to send an event whenever profile data is saved and score changes. We will test with some dummy data to verify events flow through within seconds to our storage. For non-real-time analysis, we schedule daily jobs to aggregate these events (though Snowplow’s data will already be in warehouse in near real-time, we can query anytime). With this setup, Parker Flight’s analytics will be robust and owned by us, enabling quick product iterations and personalization that is “2025-ready”.

UX Wireframe Kit
(The following presents a conceptual wireframe for the new Profile & Settings interface with five tabs. Note: actual Figma designs would accompany this text, illustrating the described elements.)
Account/Traveler Info – The profile main tab shows a completion progress bar and key personal info fields. In this example, the user’s profile is only 0% complete, and the UI prompts them to start filling in details. The design uses a friendly tone and clearly indicates how much is left to do.
Account: This first tab contains core account information and login/security settings. At the top, we display the Profile Completeness widget – a circular progress indicator or horizontal bar indicating completion percentage (e.g. “40% Complete”). Next to it, or below, a short list of recommended actions appears (if profile < 100%): e.g. “✅ Add a profile photo”, “✅ Verify your phone number” – each with an action button. This acts like a checklist to drive completion. Below that, the Account section shows basic fields: Name, Email, Phone. Email might be read-only (if it’s the login), with an option to “Change Email” which triggers a re-verification flow. Phone number field is shown with either a “Verify” button (if not verified) or a checkmark if verified. Also in Account tab, include Password & Security: if the user has a password login, a “Change Password” button. If using passwordless/Social login, this area can show “Connected accounts” (e.g. “Google account linked”). We also place Two-Factor Authentication toggle here (for future – e.g. enable TOTP or SMS 2FA for login). Finally, the Account tab might list “Personalization & Privacy” options – like language preference or an option to download their data (GDPR compliance), though those could also be separate.
Traveler Info: The second tab is dedicated to travel-specific profile details (especially for booking automation). Here the user can manage multiple traveler profiles. The UI might start with a dropdown or side menu listing travelers: e.g. “John Doe (Me)”, “+ Add Traveler”. Selecting a traveler loads their info form. For the main user’s traveler profile, the form includes Date of Birth, Gender, Nationality, Passport Info, Known Traveler Number, Frequent Flyer numbers, and any saved preferences (seat preference, meal preference). We use a progressive disclosure approach – not overwhelming with all fields at once. For example, show basic info first, then an expandable section for “Travel Documents”. Each major section can have its own mini-completion status. If multiple travelers are supported, clicking “Add Traveler” brings up a blank form to input a companion’s details. Each saved traveler is listed with their name and maybe a tag (like “Self”, “Child”, “Colleague”) for context. There should be an option to remove a traveler profile (except maybe the primary) and to edit each. We ensure the form fields have auto-format (e.g. passport number in proper uppercase, date pickers for DOB). In-context nudges: Since this info is sensitive, we include notes like “We securely store this to autofill bookings” near fields like passport. Also, if certain fields are missing, small prompts or banners might appear: e.g. “Planning international travel? Add your passport to speed up check-in.” This tab essentially replaces the old single “Profile Information” page with a more powerful multi-profile manager.
Notifications – The notifications settings tab allows users to manage how they receive different types of messages. In this mock, email toggles are on for all, SMS is pending phone verification.
Notifications: This tab offers fine-grained control over communication. At the top, if the user hasn’t verified their phone, we show an inline prompt: “📱 Add your phone number to receive SMS alerts.” In the screenshot above, there’s a phone input and “Send Verification Code” button integrated into the page. Once the phone is verified, that prompt disappears or changes to “✅ Phone verified for SMS.” Below that, we list notification categories in a clear list, each with sub-options: for each category (Booking Confirmations, Booking Issues, Flight Reminders, Price Alerts, Promotions/Marketing, etc.), the user can toggle channels. We present these as either checkboxes or toggle switches labeled “Email” and “SMS” (and later maybe “Push”). Important categories like “Booking Confirmations” might be mandatory email (can’t turn off, because it’s transactional) – as shown in the screenshot where “Required” is noted. We’ll visually differentiate required vs optional (e.g. required ones are greyed out but checked). Next, incorporate the Quiet Hours and Digest controls: for quiet hours, we could have a subsection below labeled “Quiet Hours 🕒” with an explanation “Pause notifications during these times (urgent alerts will still come through).” This would have time pickers for start and end times, and maybe checkboxes for which days it applies (weekday vs weekend). For digest, for categories like Price Alerts or Promotions that can be batched, allow a dropdown: “Send immediately / Send daily summary at [8:00 AM] / Send weekly summary [Day]”. The UI might use a combo box for frequency. We’ll color-code or group sections: e.g. “🚨 Critical Alerts (always sent)”, “✈️ Travel Updates”, “💰 Price & Deal Alerts”, etc., to help users parse easily. At the bottom, a summary like in the current UI (e.g. “Current Setup: Email: ✅ All important updates; SMS: ✅ Flight updates, ❌ marketing”) can be shown for clarity. A Save button (or auto-save toggles) ensures preferences persist. The design focus is clarity and user empowerment – they should feel, “I can control how Parker communicates with me, on my terms.”
Wallet: The wallet tab (which might be labeled “Payment” or “Wallet”) enables users to manage saved payment methods. The UI lists their saved cards in a visually recognizable way – showing card brand logos (Visa/Mastercard) and last 4 digits, maybe an icon of a card. The first card in the list is marked as “Default” (with a star or label). Each card entry has action buttons: “Set as default”, “Remove”. Possibly an “Edit” if we allow naming the card or updating expiry (though typically one would re-add if expiry changed). At the top, a prominent “+ Add Payment Method” button triggers a flow to add a new card. We can integrate Stripe Elements or Payment Request (for Apple/Google Pay) for a slick add experience. If using Payment Request, clicking add could show a system sheet to pick a saved card from the browser/phone. Otherwise, a form appears to input card details (card number, expiry, CVC) with Stripe’s secure handling. The screenshot we have shows an empty state with an error in dev, but in our new UI, the empty state would say “No payment methods saved. Add a card to enable 1-click bookings.” with the add button. For security, we may also show a note: “Your payment info is encrypted and stored securely via Stripe (PCI-compliant)”. Once cards are added, the list view should allow reordering or just clearly mark default. Removing a card prompts confirmation (“Are you sure? This will also remove the card from our secure vault.”). If a user has bookings with a removed card, we might want to warn if that card was tied to upcoming payments (though in our system likely not, since we charge immediately). Additionally, if feasible, show other wallet features: e.g. a toggle for “Use 3-D Secure for extra authentication” if we allow that, or a note if any payment failed. Given fintech trends, we could also include payment history or receipts in this section (though could be separate “Transactions” tab). However, likely we keep Wallet focused on methods of payment. The design should instill confidence – using bank/card icons, maybe the Stripe logo subtly (“Secured by Stripe”) to leverage that trust.
Security: The Security tab focuses on account protection. Some elements from Account might overlap but here we centralize them for emphasis. Items in this tab: Change Password – if applicable (clicking opens a modal or dedicated form). Two-Factor Authentication – allow user to enable TOTP or SMS 2FA for login; if enabled, show status and backup code options. Authorized Devices / Sessions – list active sessions or remembered devices with an option to log out from others (this requires tracking sessions on backend; Supabase might allow session management via its auth). Account Activity Logs – show recent login locations or security events (e.g. “Password changed 2 days ago”). Delete Account – a danger zone section where user can initiate account deletion. We’d warn and require re-auth for that action. The Security UI should use alerts and confirmations (e.g. when enabling 2FA, walk them through QR code scanning, etc.). Even if not all features are fully implemented on backend yet, designing this tab sets the stage for near-future additions. Many modern apps have a similar security settings page, so we can follow known patterns (for instance, Google account security page as inspiration).
Throughout all tabs, we maintain a consistent layout: a left-aligned tab menu (or top tabs on mobile), and a responsive design for mobile vs desktop. The style uses Shadcn/UI components meaning accessible form inputs, switches, etc., with Tailwind styling. We ensure each tab’s content has a clear heading and grouping. For example, in Notifications tab, use subheadings for “Email & SMS Preferences”, “Quiet Hours”, etc., to break up content. We also include explanatory text where needed in a lighter tone to guide users (e.g. under Quiet Hours: “We won’t send notifications during these times, except for urgent alerts like cancellations.”).
Finally, visual feedback and polish: after the user saves changes on any tab, we show a small toast “Preferences saved” or “Profile updated successfully ✅”. In the profile completeness widget, when they hit 100%, we could have an animation or a special icon (like a trophy 🏆). This makes the experience rewarding. All these UI decisions aim to make Parker Flight’s profile system feel modern, user-friendly, and on par with leading consumer apps.

Implementation Task List (Sprints S-1 to S-5)
Below is a breakdown of the implementation tasks, organized by sprint. Each task is specified with a title, description, acceptance criteria, and story points estimate. The tasks are written in a Jira-ready format, focusing on clear outcomes.
Sprint S-1: Architecture & Foundation
S1.1 – Supabase Edge Function Versioning Setup (Story Points: 3)
 Description: Create a versioned instance of the profile API function to allow parallel development of a v2 API. Update routing and documentation for versioning.
 Acceptance Criteria:
 – A new Supabase Edge Function secure-traveler-profiles-v2 is deployed alongside the existing v1.
 – The v2 function is reachable at /functions/v1/secure-traveler-profiles-v2 and returns a distinct response (e.g. includes a version field in JSON).
 – API documentation is updated to indicate v1 vs v2 endpoints and their request/response differences.
 – Existing functionality from v1 (CRUD profile) is replicated in v2 (can initially be same logic).
 – No regression: existing clients using v1 continue to work unaffected.
 Notes: This is groundwork for future changes – initially v2 may behave same as v1, but confirms versioning works.


S1.2 – Feature Flag Audit & Strategy Update (Story Points: 2)
 Description: Review current LaunchDarkly feature flags, remove or archive unused ones, and set up new flags for upcoming features. Also integrate LaunchDarkly notifications for flag changes.
 Acceptance Criteria:
 – All existing flags in LaunchDarkly are documented (purpose, rollout status) in our repo or Confluence. Unused flags are archived in LD (or deleted if safe).
 – New feature flags created: e.g. multi_traveler_enabled, profile_ui_revamp with default “off” for all users.
 – The frontend is updated to check these flags (e.g. conditionally show multi-traveler UI if flag on). Back-end also guards any new API endpoints/logic with the flags if needed.
 – LaunchDarkly Slack integration enabled: when a flag change occurs, a message posts to #dev-ops (for visibility).
 – Developers have a guide on adding new flags and removing them post-release (added to README).
 Notes: No user-facing change yet; this ensures the framework to toggle new features gradually.


Sprint S-2: Profile Experience Enhancements
S2.1 – Multi-Traveler Profile UI & Backend (Story Points: 8)
 Description: Enable support for multiple traveler profiles per user. This includes back-end adjustments and a new UI for managing additional travelers.
 Acceptance Criteria:
 – Database: Confirm traveler_profiles table supports multiple entries per user (one-to-many). Add any needed columns (e.g. relationship or label for traveler, if desired) and run migration.
 – API: Update the profile Edge Function (v2) to handle CRUD for multiple profiles. E.g., action: 'list' returns all traveler profiles for user, action: 'create' adds a new one. Ensure RLS policies allow only user’s own profiles.
 – Frontend UI: In the “Traveler Info” tab, user can click “Add Traveler”. This reveals a form for a new traveler with fields: first name, last name, DOB, gender, passport number, passport country, expiry, etc.
 – After adding, the new traveler appears in a list (or dropdown) on that tab. User can switch between profiles to edit each.
 – The UI allows deleting an extra traveler (with confirmation “Are you sure you want to remove this traveler profile?”). The primary traveler (the user themselves) cannot be deleted.
 – Booking flow impact: (if in scope) on initiating a booking, the user can select which traveler(s) to use for ticket details. If not implementing selection now, ensure the data model is prepared for it (e.g. booking can reference a traveler_profile_id). Possibly add a “default traveler for bookings” setting.
 – Testing: Create at least two traveler profiles via UI for a user, verify they save in DB and can be retrieved and edited. Verify RLS: one user cannot fetch another’s travelers.
 – All new UI text has i18n keys (for future localization).
 Notes: This is a large feature affecting UI and API. It’s behind a feature flag multi_traveler_enabled – enable the flag for internal testing, ensure when off the UI still shows only the primary profile (for gradual rollout).


S2.2 – Profile Completion Meter & Recommendations (Story Points: 5)
 Description: Improve the profile completeness indicator UI and surface personalized recommendations to encourage profile completion.
 Acceptance Criteria:
 – Progress UI: Replace the simple “Profile 0%” text with a visual progress bar or ring. It should display the percentage and a label (e.g. “Complete: 40%”). Use a component that is accessible (e.g., includes aria-label announcing percentage).
 – The progress component changes color or style when reaching milestones (optional): e.g. red/orange when low, green when near 100%.
 – Recommendations UI: If profile score < 100, show a list of 1-3 “Next steps to complete your profile.” These are generated by calling an endpoint or function that uses get_profile_recommendations() logic (which is implemented in backend). For example, if phone is not verified, one recommendation might be “Verify your phone number to increase security and get SMS alerts.” Each recommendation includes a short title and maybe a “Do it” link that navigates the user to the relevant tab/section.
 – Ensure recommendations update after user completes an action (e.g., if user verifies phone, that item should disappear on next load or next calculation). This may require recalculating recommendations on profile update events – possibly integrate with the existing update_profile_completeness() trigger so that new recommendations are stored in a table or can be fetched easily. Alternatively, compute on the fly in the frontend by checking which fields are missing, aligning with our defined criteria.
 – Gamification: Add a celebratory element when reaching 100% – e.g. a confetti animation (if easily done) or at least a special message “🎉 Profile Complete! You’re all set for faster booking.”
 – Privacy copy: next to the progress or in a tooltip, include “Why complete your profile?” info (e.g. “Completing your profile unlocks faster checkout and personalized deals. Your data is stored securely.”).
 – Testing: Use a test account to fill profile step by step and verify the meter increases correctly per field weights (as defined in backend). Confirm that each completed action removes the corresponding recommendation. Check that 100% triggers the final state.
 Notes: Some of this leverages existing backend logic (score calculation, recommendations), so ensure the frontend can call an API (maybe a new /profile/recommendations function) or perhaps we embed the logic client-side for now using the same rules. Keep it behind the profile_ui_revamp flag until ready.


S2.3 – Twilio Verify Integration for OTP (Story Points: 5)
 Description: Migrate the phone verification process to Twilio Verify API for sending and verifying SMS codes. Adjust frontend flow accordingly.
 Acceptance Criteria:
 – Backend: Create a new Supabase Edge Function (or extend an existing one) for phone verification that calls Twilio Verify. For example: POST /functions/verify-phone with {phoneNumber} triggers client.verify.v2.services(SID).verifications.create. Another endpoint POST /functions/check-phone-otp with { phone, code } calls ...verifications.check. Use Twilio Node SDK (or REST API) with our Twilio credentials.
 – The Twilio Verify Service SID and other required config are added to env vars (and not hard-coded).
 – Frontend: Update the phone verification UI component (PhoneNumberSetup.tsx) to use the new endpoints. When user enters a number and hits “Send Code”, call our function (loading state indicated). On success, show “Verification code sent to +X***”. Then allow input of the 6-digit code. On code submission, call check function; if success, show a success state (“Phone verified!”) and update the profile state (e.g. trigger refresh of user profile to get phone_verified=true). If error (wrong code), show error message and allow retry.
 – Implement a “Resend code” option after e.g. 30 seconds. Twilio Verify automatically throttles, but our UI should reflect that (disable resend button until allowed).
 – If Twilio’s pricing requires, ensure we only call verify for real phone numbers (the UI already probably restricts format). Possibly use a test environment number for dev to avoid charges.
 – Webhook: Configure Twilio Verify webhook for verification events to hit a new endpoint (if easily done in this sprint). For now, this could log events to console or insert into an audit_events table (e.g. “phone +123456 verified at time”). This is optional; main functionality is client-driven.
 – Remove or bypass old code verification logic. For instance, if we used to store a code in profiles.verification_code, deprecate that. The acceptance is that the old method is no longer reachable by UI.
 – Testing: Use Twilio’s test credentials or a real Twilio trial to simulate the whole flow. Verify that entering an incorrect code yields the appropriate error and doesn’t mark phone as verified. Test edge cases: requesting code multiple times (should always use latest code), trying to verify an already verified phone (should maybe just short-circuit with success).
 – Outcome: The user experience should remain nearly the same, but reliability should improve (no missing SMS, etc.).
 Notes: This task may overlap with Sprint 3 if we consider it backend heavy. But doing it in S2 ensures the profile basics are solid.


Sprint S-3: Notifications & Communication
S3.1 – Granular Notification Preferences (Quiet Hours & Digest) (Story Points: 8)
 Description: Extend the notification preferences system to include quiet hours and digest settings, and update the UI accordingly.
 Acceptance Criteria:
 – Database: Modify notification_preferences JSONB schema or related tables to store two new settings: quiet_hours (with subfields start and end times, and possibly days) and digest_frequency (e.g. an enum per category or overall). If using JSONB, ensure Supabase trigger or security policy can handle it. Alternatively, add columns quiet_hours_start, quiet_hours_end, etc., in profiles table for simplicity. Migrate existing data (if needed; likely everyone defaults to no quiet hours).
 – UI: In Notifications tab, include a section to set quiet hours. Use time pickers (if on web, two <input type="time"> fields). When user sets times and hits Save, the values are saved to their profile preferences. Validation: end must be != start (a 0-hr quiet period means off), possibly allow wrap past midnight. Also allow disabling quiet hours (e.g. a toggle “Enable Quiet Hours”).
 – Add a section for Digest: e.g. for Price Alerts and Promotions categories, add a dropdown or toggle group: “Real-time / Daily / Weekly”. These selections update an internal representation (e.g. we store something like "price_alerts": { "email": true, "sms": false, "frequency": "daily" }). If storing per category frequency is too complex, implement a simpler global digest setting for marketing vs transactional. But ideally, allow at least marketing emails to be weekly.
 – Backend logic: Implement logic in our notification sending pipeline to respect these settings. For example, if a price alert is triggered at 2 AM and user has quiet hours till 7 AM, we queue that notification (maybe store it in a queued_notifications table with intended send time). Or simpler: we check before sending each notification: if now is within user’s quiet hours and it’s not urgent, do not send. For digests, implement a daily job (Supabase Scheduler or external CRON) that compiles all queued notifications for each user and sends one summary email. For Sprint 3, the focus can be on storing the prefs and not sending immediate notifications from the app if quiet hours apply. The full digest email build can be a stretch goal (or even a manual process at first).
 – If using an external service (e.g. if we integrate with a notification provider later), ensure we can pass quiet hour info. But assume in-house handling.
 – Acceptance test: Set quiet hours for a test user to an interval including the current time. Trigger a low-priority notification (simulate a price alert). Confirm that the notification is not sent immediately (e.g. check that no email/SMS went out, maybe via logs or stub). Then adjust time outside quiet window and ensure it sends. For digest, set a user’s preference to “daily” for promotions, trigger multiple promotions, and run the digest job – confirm they all come in one email.
 – UI feedback: After saving, maybe show a summary like “Quiet hours: 10PM–7AM. Price alerts: daily at 8AM.” so user knows it’s set.
 – Ensure that urgent notifications (like “Booking failed”) bypass quiet hours – perhaps by design, we classify those differently and don't consider quiet hours for them. Document this behavior.
 Notes: This is complex as it touches both front and back. Might be split into sub-tasks (UI vs backend queue). For acceptance, demonstrating the settings persist and (via a manual check) are respected is enough.


S3.2 – Resend (Email) Integration for Comms (Story Points: 3)
 Description: Integrate the Resend service for transactional emails (such as verification emails, booking confirmations, and potentially the new digest emails). This ensures reliable email delivery and supports localization and templating.
 Acceptance Criteria:
 – Resend API Key is added to our environment config.
 – Create a utility module for sending emails via Resend (e.g. emails.ts with functions like sendVerificationEmail(to, code) or sendDigestEmail(to, content) etc.). Use Resend’s Node SDK or REST API.
 – Replace any existing email-sending code (perhaps we used SMTP or Supabase’s built-in email confirmation) with Resend for the relevant use cases: account verification emails, password reset emails, booking confirmation receipts, etc. For each use, either design a template in Resend or use Resend’s simple send with our own HTML template.
 – Ensure emails are sent asynchronously (the Edge Function can call Resend API and not block, or we handle response properly).
 – Testing: Trigger a test email in each category: e.g. use a dev route to send yourself a verification email and check it arrives (possibly using Resend’s dashboard if actual email not accessible in dev). Test an email with non-ASCII content if planning localization (Resend should handle UTF-8).
 – Logging: log email send events for audit (e.g. to a table or console with message ID from Resend).
 – Fallbacks: If Resend fails (network down), ensure the functions handle it gracefully (maybe return an error that triggers a retry or user message “Please try again”).
 – (Optional) If time, configure Resend’s webhook for delivery events to track bounces/unsubscribes. This might be beyond scope now.
 – The system should use Resend for the new digest emails as well. Prepare a template for “Daily Alert Digest” that lists multiple items. It can be a simple HTML list for now, branded with Parker Flight logo. Verify sending that email via their sandbox or a test.
 Notes: This task ensures our notifications (especially email) are up to production quality. Now that we allow daily/weekly emails, using a robust service like Resend (instead of say, nodemailer) is important.


Sprint S-4: Wallet & Payments Upgrade
S4.1 – Stripe Payment Method Management Revamp (Story Points: 5)
 Description: Improve the Wallet tab with full Stripe integration: support adding new payment methods via Stripe Elements, setting default, and proper deletion (detach).
 Acceptance Criteria:
 – Add Card Flow: Implement a new “Add Payment Method” modal or page. Integrate Stripe Elements (card input field) or the Stripe Payment Request button for Apple/Google Pay. On submission, use Stripe’s client SDK to tokenize the card (or Payment Request to get a token), then send that token to our backend function that attaches it to the user’s Stripe Customer (using stripe.paymentMethods.attach and maybe create customer if not exists). Alternatively, use Stripe SetupIntent for a secure card save flow. In either case, ensure PCI compliance by not touching raw card data on our server.
 – On successful add, the new card appears in the Wallet list. If it’s the first card, mark as default.
 – Listing Cards: Retrieve saved cards from Stripe instead of relying solely on our DB. Possibly call stripe.paymentMethods.list(customer) on page load (or better, maintain our DB in sync). We can have a nightly job to sync or update our DB whenever changes occur (like after add/delete). For responsiveness, likely use our DB which is updated in real-time by our add/delete operations.
 – Set Default: When user clicks “Set as default” on a card, call Stripe to set that card as default for the customer (update Customer’s invoice_settings.default_payment_method or similar). Also update our local state (e.g. mark other cards as not default). This action should reflect immediately in UI (the star moves).
 – Delete Card: When user clicks “Remove” on a card, call stripe.paymentMethods.detach(pm_id). Also remove from our DB. If that card was default, Stripe will auto-select another default; update UI accordingly (you might need to retrieve the new default or simply refresh the card list from Stripe after deletion). If no cards left, consider optionally deleting the Stripe Customer (perhaps not, as discussed). At minimum ensure our DB doesn’t reference a non-existent method.
 – UI/UX: The Wallet tab UI is updated as per the Wireframe: show card brand icons (Stripe gives brand info for each PaymentMethod), last4, exp date. Indicate default card with a “Default” badge. The add card button opens the form modal. Provide feedback: on add success, show “Card added successfully”; on remove, remove the element with maybe a toast “Card removed”. If add fails (card declined or token creation fails), show error from Stripe (“Card was declined, try another card”).
 – Include a note about security: e.g. “All payments are processed securely via Stripe” at bottom of page.
 – Backend: Ensure idempotency if the user spams add or remove (Stripe idempotency keys if needed). Also ensure our RLS or function security: only the owner can add/delete their cards.
 – Testing: Use Stripe test cards to run through add/set-default/remove sequences. For instance, add two cards, mark second as default, ensure in Stripe dashboard the default switched. Remove one card, ensure it’s detached in Stripe (check Stripe dashboard or API). Also test edge case: removing the only card – then user has none, UI should show the empty state (with add prompt).
 Notes: We assume one Stripe Customer per user was created previously (if not, we create on first card add). Document that if user deletes account, we should delete customer (that’s covered in a later task or policy).


S4.2 – Payment and Booking Integration Check (Story Points: 3)
 Description: Ensure that the booking flow uses the new wallet data properly and clean up any payment-related issues (like failing to charge if card removed). Also implement any needed changes for upcoming group booking payments.
 Acceptance Criteria:
 – If our booking engine (maybe an Edge Function or external API call) expects a payment method, ensure it pulls the default payment method or the one selected by user at booking time. Update the booking UI to allow user to select among their saved cards if multiple (a dropdown listing last4).
 – If a user has no saved card when trying to book, the app should prompt them to add a payment method (e.g. a popup “Please add a payment method to complete booking” that leads to Wallet tab). This prevents confusion.
 – Test a full booking in a staging mode: user picks a flight, goes to checkout, selects a saved card (or default is preselected), confirm booking triggers payment using that card via Stripe. If using Stripe PaymentIntents, ensure we use customer and payment_method so that saved card is charged. If using a different integration (maybe just storing card and charging later), adjust accordingly.
 – Cleanup of old data: If we stored card info in our payment_methods table (like brand, last4), verify that data is consistent with Stripe. If not, consider a one-time sync: e.g. call Stripe API for each user’s methods and update our records. This could be done via a script or admin function.
 – For group bookings: if multiple travelers and splitting cost or paying together, ensure the payment still just charges once. No immediate change needed here except to keep in mind that group booking doesn’t require multiple payments, one payment covers all tickets typically.
 – Edge cases: If a user tries to book with a removed card (possible if they had the page open then removed card in another tab), handle gracefully – the charge attempt will fail; catch the error and prompt to choose a valid method.
 – No UI changes beyond perhaps adding that card selection dropdown in checkout if not already present.
 Notes: This task is partly QA to ensure our wallet improvements cleanly integrate into the booking process. It may involve adjusting the booking function to accept a payment_method_id instead of raw card details, aligning with using saved methods.


Sprint S-5: Final Touches – Security, Accessibility & Launch
S5.1 – Security Settings Implementation (Story Points: 5)
 Description: Build out the Security tab in the profile settings, including password change, 2FA enable, and session management.
 Acceptance Criteria:
 – Change Password: If user has a password (Supabase email/password auth), the Security tab shows a “Change Password” form: current password, new password, confirm new. Implement function to update password via Supabase Auth API (or our backend function calling Supabase admin if needed). On success, show confirmation and maybe sign the user out (or ask them to re-login). If the current password is wrong or new password doesn’t meet criteria, show errors.
 – Two-Factor Auth (2FA): Provide an option to enable TOTP-based 2FA. This involves generating a secret (use an npm lib for otplib or call Supabase if it offers), showing a QR code (we can generate a data: URI QR for the secret), and then prompting the user to enter a code from their authenticator app to verify setup. If correct, mark 2FA as enabled (e.g. store a boolean and the secret in a secure place – could be in Supabase Auth’s MFA features if available). Alternatively, if SMS 2FA is desired, we could reuse phone verification as 2FA (but TOTP is more standard). Given time, TOTP is fine. Once enabled, on login, the user would need to provide code – note: implementing the entire MFA login flow might be outside scope unless Supabase supports it natively. But storing the intent is fine. We at least prepare UI and backend to save 2FA secret.
 – Session Management: Display the user’s active sessions/devices. Supabase provides last_sign_in_at for the user and maybe a way to track multiple sessions. If not readily available, simulate by showing current session and a generic “Log out of other sessions” button (which can call Supabase’s signOut() for all, using JWT invalidation by rotating the secret maybe). If possible, list by IP or device info (we might not have device info easily without building it ourselves – skip detailed listing if not feasible).
 – Delete Account: At bottom of Security tab, have a red “Delete Account” option. When clicked, ask for confirmation (maybe re-enter password or type “DELETE” to confirm). On confirm, call a backend function to perform account deletion: detach Stripe payment methods & delete customer, remove personal data from our tables (or mark account as deleted), and delete the Supabase Auth user (Supabase has an Admin API to delete user). Ensure this action is irreversible. Also, handle if user is currently subscribed to any service (not applicable perhaps). After deletion, log the user out and show a farewell message (maybe on login screen).
 – Testing: Create a test user with password, go to Security, change password (then logout and verify new password works). Enable 2FA, scan QR with an app, verify code works. Simulate login with 2FA (this might require building a prompt on login - if too much, at least ensure the secret is stored properly). Check that disabling 2FA is possible (maybe just a button “Disable 2FA” if already enabled, which removes the secret). For sessions, open two browsers, ensure “log out others” indeed logs out the first (this might involve checking refresh token invalidation). For delete, use a test account, delete it, ensure the user can no longer login and their data in profiles, traveler_profiles, payment_methods etc. is wiped or flagged (depending on retention policy).
 Notes: Some aspects (like full MFA on login) might not be fully done if not trivial, but at least the UI and data model for it can be set. The main goal is to beef up user-visible security options and controls.


S5.2 – Accessibility & Localization Compliance (Story Points: 3)
 Description: Conduct an accessibility audit on the updated UI and implement fixes for WCAG 2.2 AA compliance. Also internationalize strings and ensure RTL layout works.
 Acceptance Criteria:
 – Run an automated accessibility testing tool (e.g. Lighthouse, Axe) on multiple pages: Profile tabs, Notifications, Wallet. Resolve all serious issues flagged. For example, add missing form labels or aria-labels (the audit might catch unlabeled inputs in the new forms).
 – Focus management: Ensure that when modals open (Add Card modal, etc.), focus is trapped inside and returns to trigger on close. Ensure no element has tabindex=-1 incorrectly or is focusable but hidden. Check the focus outline is visible (tailwind default outline maybe ok, if not, add a style). In testing, confirm that you can tab through the entire Profile page and operate toggles using keyboard (e.g. spacebar on a toggle switch). Fix any element that is not reachable or operable by keyboard.
 – Color contrast: Verify text vs background contrast for all new UI elements. E.g., the progress bar percentage text on colored background must be ≥4.5:1 contrast. If our theme colors are too light, adjust them or add an outline. Use dev tools or an online contrast checker for each element (error text, placeholder text, etc.). Address any failures (maybe adjusting CSS or using a darker shade).
 – New WCAG 2.2 criteria: Check “dragging movements” (not applicable much because we have no drag gestures). Check target size – e.g. the “x” on modals or small checkboxes: are they at least 24px clickable area? If not, increase padding or make the label also clickable. Check that if any repeated inputs exist, we avoid redundant re-entry (we did by storing profile info once). Check accessible authentication: our login should avoid cognitive tests – we do (just password or code, no extra math or CAPTCHA). We might add an alternative way for users who can’t use SMS 2FA (that’s by providing TOTP, which we did).
 – Localization infra: Integrate an i18n library (like react-i18next). Mark all user-facing strings in the Profile section for translation. For now, we might only provide English and one sample other language (e.g. Spanish) for testing. But acceptance means the framework is in place: we have translation JSON files, and the UI can switch language via a setting or query param. For example, as a quick test, we manually switch to Spanish file and see that labels like “First Name” are in Spanish.
 – RTL test: Simulate an RTL locale (Arabic). Add dir="rtl" on the root HTML or body. Inspect that the layout doesn’t break: text fields should align to right, the order of form labels vs inputs still looks correct, and icons that convey direction are mirrored if needed (for instance, in a breadcrumb or arrow icons – ensure our tab icons or any arrows in toggles aren’t confusing in RTL). Fix any layout issues by adding dir:rtl styles (Tailwind’s support or manual CSS).
 – Screen reader test: Using a screen reader (NVDA or VoiceOver), navigate key flows: The profile progress should be announced (perhaps add aria-label like aria-label="Profile is 50% complete"). Form fields should have labels read properly (our code should have <label for> matching <input id>). Any decorative icons should have aria-hidden=true. Ensure the tab navigation itself is announced as tabs (use proper roles on tablist). We can use a Chrome extension or just keyboard and see if focus order is logical.
 – All identified issues in the above tests are fixed or have workarounds. Document any partial compliance (maybe AAA criteria or ones requiring extensive changes not in scope, though aim for full AA).
 – Acceptance by standards: We consider this done when we can pass an automated WCAG 2.2 AA audit and basic manual checks for the new UI components. Also, all text content from previous tasks is now externalized in a locales file, making future localization straightforward.
 Notes: This task is important to complete before launch. It might involve minor refactoring of some components or adding utility classes. Given a smaller point estimate, focus on critical accessibility; if major issues appear, address as many as possible.


S5.3 – Deployment & Launch Coordination (Story Points: 2)
 Description: Final steps to prepare for release: feature flag rollouts, documentation, and monitoring setup for the new profile system.
 Acceptance Criteria:
 – All new features (multi-traveler, new UI, etc.) are behind flags as planned. For launch, decide on a rollout schedule: e.g. enable profile_ui_revamp to internal users or 10% of beta users on staging, then 100% in production after a week. Document this plan.
 – Ensure all environment variables (Twilio, Resend, Stripe keys, etc.) are set in production and that Supabase Edge Functions are deployed in prod environment with those. Do a test run in a staging environment if available.
 – Write a short User Guide/Changelog for the support team or release notes: explaining new profile features to end users (so support can handle questions). Also update any on-boarding tutorial in the app to highlight “You can now add family travelers and control notifications in detail” etc. Possibly include an in-app tooltip for first-time after update to guide existing users.
 – Set up monitoring: for example, ensure Supabase logs or Sentry is catching errors from the new Edge Functions (like Twilio verify failures, etc.). Also set up amplitude or Snowplow dashboards to track usage of these new features (e.g. how many additional travelers added, how many users set quiet hours).
 – Plan a backup rollback: for instance, if something goes wrong with multi-traveler data, we have a migration rollback script. Having the feature flags allows us to turn things off if needed, which is good. Ensure team members know how to toggle flags quickly.
 – After releasing to production, perform a smoke test as an end user: sign up a new account, fill out profile, add a traveler, etc. Ensure everything works with real services (Twilio SMS arrives, Stripe test card can be added if using test mode or live card if in live mode but perhaps just minimal charge).
 – Performance check: the profile page should load in reasonable time (< 2s for data). The added computations (score, recommendations) are quick since either computed server-side or simple logic. Still, observe any latency and optimize if needed (maybe caching recommendations in the profile_completion_tracking table to avoid heavy recompute).
 – Sign-off: Product and QA sign off that the new profile system meets the requirements and is best-in-class. This might involve a final meeting or demo with stakeholders.
 Notes: This task wraps up the project. It might not produce code except some config tweaks, but it ensures a smooth deployment.


Each task above will be created as a Jira ticket with the given details. During each sprint, tasks can be refined further into sub-tasks if needed (especially S3.1 and S4.1 which are larger). The team will work through these sprints, delivering a fully upgraded User & Traveler Profile system on time and aligned with best practices of 2025.
________

[Then I asked the LLM how it could improve this research]

Parker Flight Profile System – Deliverables Improvement Plan
UX Wireframe Kit
The current wireframe kit can be elevated by improving clarity, consistency, and interactivity. The goal is to ensure every screen and flow is immediately understandable and aligned with modern UI/UX standards. It’s also important to address accessibility and give stakeholders a feel for the end-user journey.
Clarify Layouts & Labeling: Double-check that each wireframe has clear labels for pages and components. Use standard icons and terminology familiar to users (e.g. a hamburger icon for the mobile menu, a magnifying-glass icon for search) to meet user expectationsinoxoft.com. If any part of the layout is ambiguous, add brief annotations explaining the intended content or behavior (e.g. “Modal appears on click of this button”).


Align with Modern UI Standards: Ensure the wireframes follow current design conventions of target platforms. This includes consistent spacing, font use, and common patterns (for example, floating action buttons on mobile where appropriate). Incorporate platform-specific UI kit elements if available (e.g. Material Design components for Android, Human Interface guidelines for iOS) so that the design feels up-to-date.


Improve Usability & Accessibility: Introduce considerations for accessibility early in the wireframes. Use sufficient color contrast for text and interactive elements, even in low-fidelity mockups. Include notes on keyboard navigation or focus order for forms. All interactive elements should be large enough and well-separated for easy tapping on mobileinoxoft.com. If any images or icons are in the design, ensure there’s a way to convey their meaning with text (this can be noted in annotations, e.g. “Icon (info) – will have tooltip explaining feature”).


Incorporate Emotional Design: Even at wireframe stage, think about feedback and micro-interactions. For example, reserve space for small success messages or error hints near form fields. You might annotate these states (e.g. “Error state: field highlighted in red with message below”). Consider adding a few example transition descriptions or simple storyboard-style frames to show an important animation (like a loading spinner or a swiping gesture).


Add User Journey Overlays: To complement the static screens, provide a user flow diagram or clickable prototype. For instance, map out the Profile Completion Journey – starting from account creation, through filling out profile sections, to reaching 100% completeness. This can be done by numbering the wireframes and drawing arrows to indicate navigation (either as an overlay on the wireframes or a separate diagram). An embedded user flow (perhaps using a tool like Figma’s Prototype link) would let reviewers click through the sequence, improving understanding of how screens connect. Embedding an interactive Figma prototype in the documentation is possible and can bring the flow to lifelearn.supernova.io.


Include Multiple Scenarios: If not already covered, add wireframes for edge cases and alternate scenarios – e.g. an empty-state profile (when the user has just signed up and profile is blank), error states for failing to save profile, or a view of a completed profile with all sections filled. This ensures the design has considered the “unhappy paths” and not just the ideal flow.


Interaction Diagrams: For more complex interactions (like multi-step forms or a verification process), consider a simple interaction diagram. A flowchart or sequence diagram can illustrate states like “User clicks verify phone → shows OTP input → success → profile updated”. This can be done with Mermaid for quick text-based diagrams embedded in Markdowngithub.blog, or a visual in Figma. Such diagrams help developers and designers alike to align on the intended dynamics beyond static screens.


State of the Art Report (All Tracks)
The state-of-the-art report is a foundation for informed decision-making, so it should be comprehensive, current, and easy to digest for both technical and non-technical stakeholders. We recommend expanding its depth with recent data, improving its visual appeal, and ensuring it covers best practices across all relevant areas.
Depth and Citations: Verify that each claim in the report is backed by up-to-date sources. If some research is shallow or missing references, conduct additional research to fill those gaps. For example, if the report discusses user profile gamification or reward systems, include a recent case study or statistic from 2024/2025 to support it. The report should cite credible industry research (e.g. Nielsen Norman Group for UX, or ACM/IEEE for technical topics) so readers trust the findings. Ensuring the research reflects the latest trends (such as personalization via AI, or new privacy regulations effective 2024) will make it more relevant – a stronger foundation for Parker Flight’s decisions.


Organization by Tracks: If “All Tracks” means the report covers multiple domains (UX/UI, database, security, performance, etc.), consider splitting the report into clearly labeled sections for each track. For instance: UX Best Practices, Backend Technologies, Competitor Features, Security & Compliance, etc. This way, readers can easily focus on the area they care most about. Start the report with a short Executive Summary that highlights key findings from each track in a few bullet points – this aids product managers who need the gist quickly.


Current Examples & Screenshots: Augment the textual analysis with vivid examples. If the report mentions competitors or analogous systems (e.g. how other travel apps handle profile completion or loyalty integration), include screenshots of those systems for illustration. A small, captioned image of a competitor’s profile completion progress bar or settings page can make the insights concrete (you can capture publicly available images or use official case studies). Ensure images are properly cited and have descriptive captions. Including 2–3 standout examples (with brief analysis under each) will break up the text and keep the reader engaged. The examples should be recent – for instance, highlighting a 2023 redesign of a major airline’s account page – to demonstrate state-of-the-art visuals and interactions.


Visual Summaries: Where possible, convert data into visual form. If the report covers a comparison of features (e.g. Parker vs Competitor A vs Competitor B on certain criteria), you might present that as a comparative table or chart in the report. Even a simple bar chart or radar chart summarizing feature coverage or performance metrics across systems could communicate insights faster than paragraphs of text. Use color or icons to call out notable differences.


Highlight Best Practices: Make sure the report explicitly calls out any industry best practices that Parker Flight should emulate. This could include guidelines like “Profiles should allow social sign-in for speed” or “Include progressive disclosure to avoid overwhelming new users.” If any best practice is missing from the current deliverables, add it with supporting rationale. For example, if accessibility hasn’t been addressed in the report, add a section about accessibility standards for user profiles (WCAG guidelines) and note how leading products incorporate them (such as offering screen-reader friendly profile editors, high-contrast modes, etc.).


Simplify Where Needed: If some sections are overly academic or dense, translate them into plainer language or actionable insights. The report should bridge research to practice. For instance, instead of a long paragraph on “modern encryption algorithms for profile data”, present a short note like “Use bcrypt or Argon2 for password hashing (current standard) – ensures compliance with OWASP recommendations.” Technical readers will appreciate concise recommendations tied to research. Non-technical readers will appreciate when jargon is minimized or explained (consider a glossary for any unavoidable acronyms).


Visual Appeal and Formatting: Apply consistent styling to make the report easy to scan. Use bold to highlight key terms or conclusions, and bullet lists for sets of recommendations. If the report is lengthy, include a Table of Contents. You can also use call-out blocks for important insights or quotes from sources (e.g., a sidebar quoting a UX statistic). If the platform allows, collapsible sections could hide detailed methodology or extended quotes, so that the main narrative stays focused. This way, someone skimming sees only the high-level points, while an in-depth reader can expand the sections for more detail.


Ensure Recency: The tech and UX landscape changes quickly, so double-check that the content is up-to-date as of 2025. For example, mention the rise of LLMs for user profile personalization if relevant, or new browser features that could impact implementation (like any new Web API for storing profile info offline, etc.). A state-of-the-art report should feel “fresh” – readers should not wonder if it might be outdated. Even a line like “As of 2024, no major airline offers feature X” or “In 2025, users have come to expect Yinoxoft.com” helps anchor the report in the current context.


Gap Analysis Matrix
The gap analysis matrix is most useful when it clearly highlights differences and their significance at a glance. We can improve it by refining the scoring system, adding visual cues, and elaborating on the insights behind the numbers.
Intuitive Scoring System: Re-evaluate how the scoring is presented. If it’s a numeric scale (say 1–5 or 0–10), ensure there’s a legend or labels (e.g. 5 = excellent, 1 = poor) so it’s self-explanatory. It may be clearer to use qualitative labels instead of just numbers, for example: 🟢 “Fully meets requirement”, 🟡 “Partially meets”, 🔴 “Does not meet”. This gives an immediate visual signal of where Parker Flight stands. If a numeric score is kept, consider also expressing it as a percentage or level (“3/5 – Moderate”) for clarity.


Use Visual Emphasis (Heatmaps or Icons): Rather than a plain text table, add conditional formatting to draw attention to high and low points. A heatmap-style color background in each cell can indicate the magnitude of gaps – e.g. green for strengths, red for weaknesses, yellow for middle-ground. This leverages pre-attentive processing so viewers spot problem areas instantlycontextqa.com. If using colors, also include icons or patterns for those with color-vision deficiencies (for example, ▲ for above average, ▼ for below). Even simple icons like ✅, ⚠️, ❌ in the matrix can convey “met”, “partial”, “not met” at a glance. The key is to transform the matrix from a dry grid of data into a visually intuitive summary of gaps.


Ensure Sufficient Detail: Check each comparison point in the matrix – is it clear why a gap exists? If any cell’s meaning could be unclear, add a brief note or footnote explaining it. For instance, if Parker Flight scores “2” in Profile Personalization vs. an ideal “5”, provide context: perhaps Parker only offers basic personalization (name, avatar) whereas competitors use full customization (themes, content preferences). These explanations can be in parentheses in the cell or as a separate write-up below the matrix. Avoid any impression of superficial judgment; tie scores to concrete observations from the state-of-the-art research.


Highlight Key Gaps: Use the matrix to tell a story by emphasizing the largest gaps. You might add a row at the bottom or a side summary: “Top 3 Gaps to Address:” listing the items where Parker is furthest behind. This directs focus to what matters most. For example, if “Mobile Profile Management” is significantly weaker than industry standard, mark it clearly. Product managers can then immediately grasp priorities from the matrix.


Consider Visualization Alternatives: If the matrix is very complex or dense, an alternative visual could be beneficial. A radar/spider chart is one option – plotting Parker vs competitors across dimensions, to literally show the “gap area”. Or a simple bar chart per category (with two bars: Parker vs Best-in-class). These visuals can be included alongside the matrix for those who digest charts better than tables. However, keep the matrix too (text is easier for precise values and is accessible). The combination of both can cater to different audience preferences.


Polish Formatting: Ensure the matrix is easy to read: proper alignment, not too small font, and maybe zebra-striping rows for readability. If it spans many columns, repeating the header row on each page (if in a doc) can help. Group related rows into sections (e.g. “UX/UI”, “Security”, “Features”) with a sub-header if that helps logically chunk the information.


Example Improvement: For instance, a portion of the improved matrix might look like:


Aspect
Parker Flight
Industry Benchmark
Gap Analysis
Profile completeness UI
🟡 Partial (70%)
🟢 Full (95%)
–25% Needs progress bar & tips
Mobile editing support
🔴 No native app support
🟢 Rich native apps
High gap – Mobile app lacking
Security (2FA)
🟢 Yes (optional)
🟢 Yes (standard)
Minimal gap (just docs)



 Here color-coding and brief notes (“Needs progress bar & tips”) immediately convey where improvements are needed. This kind of presentation makes the matrix far more actionable.


Architecture & Library Recommendations
The architecture and library recommendations should clearly explain not just what choices are being made, but why – including trade-offs – and guide the development team on how to execute them. We can enhance this section by making the reasoning more explicit, using diagrams/code for clarity, and ensuring the migration plan is thorough.
Clearly State Trade-offs: For each major recommendation (whether it’s adopting a new framework, migrating to a microservice architecture, choosing a specific library, etc.), add a concise “Pros and Cons” or “Trade-offs” discussion. Developers and architects will trust a recommendation more if they see you’ve considered alternatives and potential downsides. For example: “Switch to MongoDB for user profiles – Pros: flexible schema for evolving profile fields, high scalability; Cons: eventual consistency issues, added complexity in data migrations.” If the original text only lists the chosen solution, add why it was chosen over others. Use bullet points or a comparison table to make this easy to scan. This transparent evaluation of options aligns with best practices in architecture decision recordsdev.to.


Developer-Friendly Explanations: Avoid or explain any abstract jargon. If recommending “progressive back-end decoupling using an event-driven approach,” briefly explain what that means in practice (e.g. “i.e., the profile service will publish events like ‘ProfileUpdated’ to a message queue, allowing other services to react without tight coupling”). Whenever possible, link the recommendation to concrete code or project structure. For instance, “We will create a new service profile-service (a Node.js Express API) separate from the monolith – lives in /services/profile/ directory. The existing user module in the main app will be refactored to call this service via REST.” By referencing specific modules or file paths, you make the plan more tangible for engineers. In the current summary, they did this well by mentioning the ProfileCompletenessService in the codebase; extend that approach to all relevant recommendations.


Use Diagrams for Architecture: A visual diagram can convey the high-level architecture far more clearly than paragraphs. Include a system architecture diagram showing how components (frontend, backend services, database, third-party integrations) interact after the recommended changes. For example, a simple diagram might depict the frontend -> profile API -> database, and how an analytics service or third-party identity verification connects. You can use Mermaid to embed this directly in the documentationgithub.blog. For instance:

 mermaid
CopyEdit
flowchart LR
  User-->Web_App_Frontend
  Web_App_Frontend-->Profile_Service
  Profile_Service-->PostgreSQL_DB
  Profile_Service-->ThirdPartyID[3rd-Party ID Verification]
  Web_App_Frontend-->(Queue)-->Analytics_Service
 (The above is an example illustrating a decoupled profile service and an async analytics service; adjust to Parker Flight’s context.) Such a diagram helps new engineers quickly grasp the big picture architecture.


Include Code Samples for Library Usage: When recommending a new library or technology, provide a brief example of how it will be used. This makes the recommendation more concrete and eases adoption. For instance, if suggesting to use Passport.js for authentication or a new validation library, show 5-6 lines of example code configuring it, highlighted with Shiki for readabilitydocs.astro.build. For example:

 typescript
CopyEdit
// Using Zod for schema validation (example)
import { z } from "zod";
const ProfileSchema = z.object({
  email: z.string().email(),
  phone: z.string().optional()
});
const result = ProfileSchema.safeParse(inputData);
if (!result.success) {
  console.error(result.error.format());
}
 By including a code block like above (properly syntax-highlighted), developers can immediately see how a library improves things (in this case, cleaner validation). This also proves that the recommender has hands-on understanding of the tool, increasing trust.


Migration Steps & Phasing: Ensure the recommendations section outlines a realistic migration or implementation plan. If we are moving from the old system to a new architecture, break it into phases or steps. For example: Phase 1: Set up new Profile Service (read from existing DB, no writes yet), Phase 2: Migrate write operations to service, Phase 3: Gradually port front-end to new API, Phase 4: Retire old profile module. Each step should have success criteria and fallback considerations (for instance, how to roll back if a phase fails). If the deliverable already has a migration plan but it’s high-level, add more detail such as time estimates, owner roles (who will do it), and any required resources or tooling. This makes the plan actionable.


Address Pain Points & Edge Cases: Call out how the new architecture will handle known challenges. For example, if currently profile data caching is an issue, mention how the new approach uses Redis caching (if recommended) to improve performance, and what cache invalidation strategy will be used. If data consistency was a concern, explain how the new solution mitigates it (maybe using transactions or an eventually-consistent approach with user messaging about recent changes). By preemptively discussing these, you demonstrate a thorough design and help developers anticipate implementation details.


Reference Relevant Best Practices: If applicable, tie recommendations to industry standards or known frameworks. E.g., “Follow the MVVM pattern for the frontend to better separate concerns – this is in line with how modern React apps structure code.” Or if adopting a library, “This library is supported by the community (15k stars on GitHub) and follows OWASP security guidelines.” This not only strengthens the argument but provides external resources for devs to consult if needed.


Conciseness and Focus: While depth is good, keep each recommendation focused. If a recommendation covers multiple changes at once, consider splitting it. For instance, separate “Backend architecture changes” from “Library upgrades” sections. That way, a developer interested in database changes can read that subsection alone. Use subheadings like Frontend / Backend / DevOps if multiple domains are covered. This improves scannability of the document.


Sprint Task List
The sprint task list is where the rubber meets the road – it needs to be crystal clear for engineers to execute and for PMs to track progress. We can refine the task breakdown, wording, and acceptance criteria to ensure each ticket is actionable and testable, and the whole list presents a logical roadmap.
Granularity of Tasks: Review the size of each user story or ticket. Each task should be achievable within a sprint (or even a few days). If any task sounds too big (“Implement new profile system” as one item), break it down into smaller slices. Conversely, if tasks are overly granular (every minor subtask listed), group them into a meaningful chunk that delivers a tangible piece of value. For example, instead of separate tickets for “Create profile API endpoint” and “Write validation for profile API”, combine into one story “API: Update Profile Endpoint with Validation” with both aspects in the acceptance criteria. Aim for each task to represent a coherent functionality or deliverable increment.


Clear Titles and Descriptions: Rewrite any vague task titles to be specific. A good format is “[Module/Feature]: [Action or outcome]”. For instance, “Profile Completion Widget: Display progress bar and percentage” is more informative than “Add progress bar”. In the description, provide context or rationale if not obvious (e.g. “This allows users to see how much of their profile is filled out and encourages completion”). This helps new engineers understand why the task matters.


Acceptance Criteria that are Testable: Every user story or ticket should have concrete acceptance criteria (AC) that define “done”. Go through each task and ensure AC are written as checkable statements or scenarios. They should cover positive case, negative case (if applicable), and edge cases. For example, for a profile completeness progress bar task, AC might include:


“Progress bar accurately reflects the completeness percentage (e.g., 50% when half the fields are filled) – verified by various profile data setups.”


“If profile is 100% complete, display a congratulatory icon and lock the progress bar at 100% (no further action needed).”


“If profile is empty, show 0% and a prompt to start filling in details.”
 Each criterion should be something a tester or developer can validate as done (either via UI testing or unit tests). Writing AC in a Given/When/Then format (Behavior-Driven Development style) can also improve clarity: e.g., “Given a user with no phone verified, when they visit profile, then a recommendation to verify phone is shown.”


Grouping and Phasing: Organize the task list in a logical order, ideally mirroring the implementation sequence or feature grouping. You might cluster tasks into Epics or Sprints. For example, group all tasks related to “Profile UI/Front-end”, separate from “Backend Services” tasks, separate from “Data Migration” tasks. Within each group, order them roughly by priority or dependency (some tasks must be done before others). You could even number the tasks or label them “Sprint 1, Sprint 2, …” if the execution is planned that way. This gives the team a roadmap feel – they can see the plan unfold over time. Roadmap readability improves when tasks are not just a flat list but a structured plan.


Include Dependencies: In the task descriptions or as part of the list structure, note if a task depends on another. For instance, “Deploy new database schema” should happen before “Implement API changes for new schema”. If using a table or list format, you can indent or reference the dependencies. This prevents an engineer from picking up a task that can’t be done yet and signals to the PM how to schedule the work.


Quality and Testing Tasks: Check if the list includes tasks for QA, code review, or other quality steps. Often project plans forget to explicitly list testing. Adding tasks like “Write unit tests for profile scoring algorithm” or “QA verification of profile UI on mobile and desktop” can be beneficial. These ensure that “Definition of Done” includes quality. Acceptance criteria can also double as test cases, but calling out testing tasks emphasizes the expectation.


Documentation & DevOps: If any tasks around documentation, deployment, or DevOps work (like updating CI/CD, monitoring dashboards for the new profile service) are needed, include them as well. This gives a fuller picture of work. For example, “Update API docs for Profile endpoints” or “Add profile service to Docker compose and CI pipeline”. Often these are missed and cause last-minute rush; planning them in the sprint list is a proactive improvement.


Example Revised Ticket: Before: “Make profile verification progressive – 3 levels”. After: “Feature – Progressive Verification Levels: Implement Basic, Enhanced, Premium verification logic in profile system. Acceptance Criteria: (1) Users start at Basic by default. (2) Upon adding a passport and verifying phone, user moves to Enhanced; system reflects this in UI and data. (3) Upon completing all profile info and passing ID verification, user attains Premium; features X, Y become available. (4) Each level change triggers an event log entry.” This rewrite makes the outcome and how to validate it much clearer. It also ties into specific functionalities to develop (UI reflection, data flags, logging).


Roadmap Communication: Consider presenting an overview before the detailed list, e.g. a one-paragraph narrative: “Sprint 1 focuses on backend foundation (database, services), Sprint 2 builds the core front-end components (profile widget, forms), Sprint 3 integrates and refines, Sprint 4 is polish and QA.” This orients everyone. You could even include a simple Gantt chart or timeline graphic if useful, but a structured list might suffice since we’re in Markdown text format. The key is that from the top-level view, anyone can see how the project will progress.


Presentation & Format
Enhancing the presentation of these deliverables will make them more digestible and authoritative. Improvements can be made in layout, navigation, and use of modern documentation features. We want the documents to look professional and be easily scannable, instilling confidence in readers. Here are format and layout suggestions:
Consistent Layout & Styling: Apply a uniform style guide across all documents. For example, use the same heading levels and terminology in each deliverable (if one section is titled “Architecture Recommendations”, avoid calling it “Tech Stack Suggestions” elsewhere – consistency reduces confusion). Use Markdown features for clear hierarchy: # for main titles (as used here), ## for sections, etc., so the rendered output has an obvious structure. Ensure each document starts with a strong title and an introduction describing its purpose.


Scannability: Break up long paragraphs (as we are doing here) into shorter chunks. Use bulleted or numbered lists for enumerations (steps, features, criteria) – readers' eyes gravitate to bulleted lists when scanning. Key points or decisions can be bolded. Also consider using blockquotes or call-out blocks for highlighting important notes (some documentation systems allow styling notes as info/warning boxes).


Embedded Diagrams and Images: As mentioned in earlier sections, adding diagrams (via Mermaid or embedded images) can hugely improve comprehension. For instance, an architecture diagram in the architecture doc, a user flow diagram in the UX doc, or a screenshot in the state-of-art doc. Place these visuals strategically at the point in the text where they illuminate the discussion. When embedding images, always accompany them with a caption or at least refer to them in text (e.g. “(See figure above for reference)”). The platform rules suggest citing image sources at the paragraph start for proper attribution – do that for any borrowed images.


Figma Embeds for Design: If the output medium supports it (for example, if these deliverables are viewed in a web browser or a tool like Notion/Confluence), you could embed live Figma frames. A Figma embed would allow product managers to play with a prototype or inspect the design components in detaillearn.supernova.io. If direct embed isn’t feasible, even a static exported image of the Figma wireflow with clickable link to the live prototype is great. This provides a richer context than flat images.


Collapsible Sections: For lengthy detailed content (like the full list of research references or a code appendix), use collapsible sections to hide the less crucial info by default. Many markdown and documentation systems allow a <details> tag or a similar collapsible block. For example, the state-of-the-art report could hide the exhaustive reference list or methodology, so a reader sees the key findings first and can expand the rest if interested. This technique keeps the documents tidy and focused.


Code Formatting: Wherever code is present (e.g. in architecture or sprint docs), format it properly in code blocks with language specified for syntax highlighting. Using a tool or integration with Shiki will ensure the code appears with colored syntax, improving readabilitydocs.astro.build. Also, if showing config files or JSON, those should also be in code blocks (with JSON highlighting). If the documentation platform allows code tabs – that is, multiple code snippets side by side for different languages or contexts – consider using that for showing alternatives or before/after code. For instance, showing pseudocode vs actual code, or a snippet of current implementation vs new implementation. This can be an effective way to communicate changes to developers.


Tables and Matrices: Ensure tables (like the gap analysis matrix) are properly formatted in Markdown so they render cleanly. Use bold headers and maybe slight styling (if possible) to make them visually appealing. Avoid overly wide tables that require horizontal scrolling; it’s better to break them or rotate the content if needed.


Navigation Aids: If the deliverables are separate files, include cross-links between them. For instance, the architecture doc could link to the gap analysis when referring to specific shortcomings it addresses. Or the state-of-art report can reference “see Gap Analysis Matrix for summary of how we stack up”. In an HTML or wiki context, these would be hyperlinks. In Markdown text, just clearly naming the other document is helpful. Also, each document on its own could benefit from an internal mini table of contents if it’s long (many Markdown processors auto-generate one if you have headers).


Polish and Professionalism: Little things like using the Parker Flight branding (logo or colors) in the docs (if appropriate) can add to the professional feel. Also, correct any typos or inconsistent terminology. Using the same tone and voice across sections (e.g. either all imperative or all descriptive) makes it read as a cohesive package. If possible, have a cover page or header section at the start of the whole deliverable set, listing each document (Wireframes, Report, etc.) with a brief description – like an overview page. This acts as a guide for anyone navigating the deliverables.


In summary, treat the presentation as you would a product: iterate on layout, test that someone can find info quickly, and use modern documentation tools (Mermaid for diagrams, Shiki for code, Figma for design embeds) to enhance clarity and engagementgithub.blogdocs.astro.build.
Developer Usability
Finally, we evaluate how usable these deliverables are for a developer, especially someone new joining the project. We want the new engineer to ramp up quickly using these docs. The improvements below focus on clarity of terminology, linking information to the codebase, and providing guidance that connects plan to implementation.
Onboarding Perspective: Consider adding a short “How to use this document set” section for new engineers. This could be a few sentences at the start of the main readme or overview, explaining the purpose of each deliverable and the order to read them in. For example: “If you’re new to the project, start with the State of the Art Report to understand context, then see the Architecture Recommendations for our planned approach, review the Wireframe Kit for UI guidance, and finally use the Sprint Task List to jump into current work.” This roadmap prevents a newbie from feeling lost.


Define Terms and Acronyms: Audit the documents for any term, acronym, or Parker-specific jargon that might not be universally known. The first time each appears, add a brief definition. For instance, RLS is used in the architecture doc – it was properly spelled out as “Row Level Security” with a note on what it means, which is excellent. Ensure similar treatment for things like “progressive disclosure” (explain it means revealing additional fields as needed), “ADR” (if you mention architecture decision record), etc. You can use footnotes or a glossary section for this purpose. A glossary at the end of the document can list all key terms alphabetically for quick reference.


Link to Code and Repos: Where possible, tie recommendations or tasks to actual code locations. The deliverables already hint at this (e.g., referencing a TypeScript service file). We can expand that. For instance, if the architecture calls for a new module or refactoring an old one, mention the module name or path. In the sprint list, tasks can include file hints (e.g., “Update TravelerProfile model in backend/models/profile.js to add new fields”). In architecture recommendations, if we say “introduce caching layer”, mention which service or if a new repository will be created for it. These concrete references act like breadcrumbs for a developer to follow from documentation to implementation.


Examples and References: Provide examples of usage for any new pattern. We did this in the recommendations (code snippets). Additionally, if adopting a known design pattern or library, include a link to its documentation or a known usage in the existing code. For instance, “We will use Redux for state management (our app already uses Redux in the Booking module, see bookingStore.js for reference on pattern).” This not only educates the newcomer but also reassures them that there’s precedent or resources to look at.


Cross-Referencing Decisions: If some decisions were based on certain research findings or stakeholder inputs, mention that and reference the source (could be within these docs). For example, “We chose to implement two-factor authentication (2FA) based on the security gap identified in the gap analysis matrix (Gap Analysis – Security row).” By doing so, a developer sees the rationale and can dig deeper if needed. It also shows that decisions weren’t made arbitrarily, increasing trust.


Ensure Practicality of Steps: Walk through a few key use-cases from a developer standpoint to see if anything is missing in the plan. For example, a new dev trying to implement the profile completeness algorithm – do they have what they need? The docs mention the formula, but perhaps providing a reference to where it should be implemented (like “this will go into the existing calculate_profile_completeness() DB function or an equivalent in service layer”). The Architecture Implementation Summary that was provided is a good model: it enumerated what was implemented and even gave code-level details. Emulate that clarity in forward-looking documents too. Essentially, anticipate the questions a developer might ask (“Where does this code live? How do I test this? What if X fails?”) and preemptively answer them.


Tooling & Environment: Make sure environment-related info is available. If a new library is recommended, note if new packages need to be installed or new environment variables will be required. If data migration is part of plan, mention if a migration script will be added (and where). These operational details are often overlooked but very important for the person who has to actually run the code.


Feedback Loop: Encourage developers to treat the docs as living. Perhaps include a note like, “Developers: if you find any discrepancies or have suggestions, please update this document or inform the tech lead.” This invites engagement and keeps documentation relevant. A newcomer who spots outdated info will know it’s okay to surface that.


Example – Linking to Repo: Suppose the plan says “Implement new endpoint for profile photo upload.” Enhance that by saying “in the user-profile-service repo, under routes/profile.js.” If the project uses a monorepo, specify the path. If multiple repos, name which one. The user shouldn’t have to guess; the docs should direct them right to the relevant part of the codebase. This is akin to how the summary file mentioned the ProfileCompletenessService in src/services – such context is gold for a developer onboarding.


Make It Searchable: If these deliverables will live in a knowledge base or repository, ensure they are indexed or searchable by key terms. Sometimes simply using consistent terminology helps (e.g. always call it “Profile Completeness Score” rather than alternating between “profile score” and “completion percentage” in different places). That way, a search in the repo or docs will find all relevant mentions. This is a subtle point, but it aids usability significantly in practice.


Address Security/Privacy for Devs: One area developers will be cautious about is handling of user data. If not already covered, add notes on compliance (GDPR, etc.) and how the system addresses them. For example, “All personal data fields are encrypted at rest using AES-256, see config in config/secrets.yml.” Or “Users have the right to delete profile info – we will implement a deletion script (see Sprint task X).” These notes align development with legal/ethical requirements and prevent nasty surprises later.


Confidence and Trust: By implementing all the above improvements, the deliverables will exude thoroughness. This boosts trust not only for developers but for product managers and other stakeholders. A new engineer reading these will feel the project is well thought-out and that they have a clear playbook to follow. A product manager will see that every recommendation and task is backed by reasoning or data (we’ve added citations and best-practice references liberally), which increases their confidence in the plan.


In conclusion, by refining content in each deliverable (UX, research, analysis, architecture, tasks) and upgrading the format and clarity, we transition the Parker Flight Profile System documentation from good to great. These changes will make the plans more actionable for engineers, more convincing for stakeholders, and easier for everyone to navigate and trust. Adopting tools like Mermaid for diagrams, Shiki for rich code examples, and Figma for interactive design embeds will provide a modern, polished touchgithub.blogdocs.astro.buildlearn.supernova.io. The end result is a set of deliverables that not only contain the right information but present it in the best possible way – driving the project forward with a shared understanding of excellence.

[Then simultaneously we ran similar research in a different chat]

Parker Flight Profile System – State of the Art & Recommendations
Track A – Product & UX Benchmarking
Profile Completion UX Patterns
Modern travel and fintech apps employ gamified profile completion indicators to encourage users to fill in their information. For example, apps like Wise and Revolut use progress bars or rings, badges, and challenges to drive engagement. These visual cues (often shown as a “Profile 80% complete” ring or a checklist of missing fields) tap into gamification principles to reward users for completing their profiles. LinkedIn pioneered this approach with its “Profile Strength” meter, and many newer apps have adopted similar progress trackers to nudge users through incremental onboarding.
Providing immediate feedback and a clear path to 100% completion reduces user uncertainty and increases motivation. Hopper and Airbnb (travel apps) show onboarding checklists and status bars (e.g. “Add a profile photo to reach 100% and earn a badge”), making the process feel like a challenge rather than a chore. This progressive disclosure strategy – asking for a bit of info at a time – prevents overwhelming the user. It aligns with Parker’s need for incremental data collection, addressing the current gap where all information is requested upfront, causing friction.
Beyond visuals, reward mechanisms can reinforce profile completion. Some fintech apps give points or unlock features when profiles reach 100% completeness. For instance, Ramp (finance) and Robinhood might grant higher spending limits or a referral bonus once identity is fully verified (a natural incentive to finish profile setup). Badges like “Verified Traveler” on airline apps or tiered profiles (“Bronze” vs “Gold” completeness) create a sense of achievement.
Wallet Integration & Payment Info UX
Best-in-class apps seamlessly integrate payment wallets into the profile section, making it easy to add or manage payment methods. Google Flights and Kayak let users save traveler credit cards in profile so bookings can be one-click. The key UX pattern is a dedicated “Wallet” tab (or section) in the account profile, often with an “Add Payment Method” call-to-action that uses familiar logos (Visa, PayPal, Apple Pay) for trust. For example, Airbnb’s profile has a Payments & Payouts section where users can add cards or bank accounts with minimal input – leveraging card scanning or autofill to reduce friction.
High-UX apps also indicate why adding a payment method is beneficial (e.g. “Save a payment method for 1-tap checkout on future bookings” or “Wallet info is securely stored to speed up reservations”). This addresses Parker’s need to explain data collection benefits. Delta’s mobile app (airline) integrates the wallet by allowing users to scan their credit card and save it to profile – showing a lock icon and copy like “Secured by Stripe – we never store your full card number” to build trust. This kind of trust-building copy reassures users about security and encourages them to input sensitive data.
Another pattern is guiding users through wallet setup during onboarding: Hopper prompts new users to “Add a payment method now for faster deal bookings,” perhaps offering a small travel credit for doing so. Wise (fintech) similarly asks users to add money or link a bank early on, gamifying it by showing progress towards an “account setup” checklist. Parker Flight can adopt these UX cues: a wallet tab with a progress indicator (e.g. “2 of 3 payment methods added”) and context like “Save a backup card to avoid booking interruptions”. This addresses a current Parker weakness: while Stripe integration exists, the UI does not currently highlight wallet setup or its importance.
Notification Settings & Preferences UX
Top apps provide granular, user-friendly notification preference centers rather than a simple on/off switch. For instance, Slack’s notification settings (though a workplace app) are often cited for best practice: Slack allows users to choose which events trigger alerts, set specific quiet hours, and pick channels (mobile push vs. email). In the travel domain, Skyscanner and Hopper let users toggle alerts for price drops, gate changes, trip reminders, etc., each with email/SMS/push options. The UX pattern is a list of notification categories (e.g. Booking confirmations, Flight status updates, Promotional offers) with checkboxes or toggles per channel. This aligns with Parker’s JSON-based notification_preferences but goes further by exposing controls in a clear UI.
Crucially, leading apps also let users schedule notifications or choose digest frequency. Microsoft Teams and Apple’s iOS offer Do Not Disturb windows (quiet hours) so users won’t be pinged at 3am. For example, a user might set “Do not send SMS between 10pm–7am”, especially important for global travelers. Parker should implement a similar “quiet hours” setting to respect user downtime. Additionally, digest options are a modern trend: Quora lets users opt for a daily or weekly summary instead of instant notifications. Many users appreciate a single daily digest email to reduce notification fatigue. Providing these choices can increase user satisfaction and compliance with regulations (e.g. GDPR’s focus on user consent for communications).
In terms of UX copy, top apps explain why each notification is useful. They employ microcopy like: “Get flight delay alerts by SMS so you don’t miss updates” or “Enable marketing emails for special fare sales.” This contextual explanation builds trust that notifications are user-centric, not spam. Parker’s current implementation has basic toggles; by adopting the above patterns (category breakdown, channel toggles, scheduling, digest options), Parker can greatly enhance usability. Research shows users value granular control – without it, they may resort to turning off all notifications (or marking emails as spam). A well-designed preference center, as advocated by SuprSend’s 2024 guide, serves as tangible proof of user consent and control.
Explaining Data Collection & Building Trust
Users are more willing to complete profiles when apps clearly communicate why data is being collected. Gold-standard apps integrate explanatory text and just-in-time prompts to this effect. For example, Airbnb emphasizes trust and safety: on identity verification steps, Airbnb’s UI notes “Verifying your ID helps build trust in the community and may be required by hosts”. Similarly, Delta’s app might explain “We ask for your passport info now so check-in is faster later”. Autofill benefits are often highlighted – e.g. Google Flights or Kayak informing users that saving traveler details will enable one-click form filling during bookings. This addresses the “what’s in it for me?” question. Parker should incorporate such messaging at key points (for instance, next to the Passport Number field: “Saved securely and used to auto-complete visa forms when you book”).
Privacy and security assurances also increase completion rates. Fintech apps like Wise and Robinhood often include brief notes or tooltips (🛈) next to sensitive fields: “Your data is encrypted and used only for compliance”. Parker’s architecture already has strong security (KMS, encryption), so surfacing that in the UI is beneficial. For example, showing a lock icon and text “Protected by bank-grade encryption” near personal info fields can reassure users. Transparency is key – Wise is cited for its radical transparency, even emailing users how fast their transfer was processed to highlight an unnoticed benefit. Parker can similarly let users know why phone verification or ID verification is useful (“Verified phone numbers help us reach you with gate changes – and protect your account with 2FA”).
In summary, apps in 2023–2025 focus on user empowerment and education: progress indicators to encourage action, minimal but clear explanations to justify data asks, and trust signals (badges, encryption icons, compliance notes) to allay fears. Parker’s current profile UX lacks these elements. By adopting these patterns from industry leaders (Airbnb, Google, Wise, Slack, etc.), Parker can expect higher profile completion rates and improved user sentiment. Notably, progressive onboarding and clear value propositions for each profile field will turn what is today a “form filling” exercise into a guided, even enjoyable, experience.
Track B – Engineering Architecture Best Practices
B.1 API Versioning Strategy (Supabase Edge Functions)
Current challenge: Parker’s primary profile API is an Edge Function deployed at /functions/v1/secure-traveler-profiles. The question is how to evolve this API without breaking clients – essentially, how to do API versioning in Supabase’s serverless environment.
Best practice: Versioning should be approached by namespacing the function or routing logic. Supabase does not natively support multiple versions of the same function name loaded concurrently (the v1 in the URL is Supabase’s own version prefix, not the user’s). A pragmatic solution is to include the version in either the function name or the path handled by a function router. For example, Parker could deploy a new function secure-traveler-profiles-v2 for the next version. Clients would call /functions/v1/secure-traveler-profiles-v2 while legacy clients continue on ...profiles (v1). This straightforward approach (“version in name”) is easy to implement and makes it explicit which version is in use.
Alternatively, one can implement a routing layer in a single function: e.g. a top-level Edge Function that reads a version number from the request path or payload and then dispatches to the appropriate logic internally. This requires a bit more code (using a router library like itty-router or Oak inside the Deno function) but keeps one deployment entrypoint. If Parker expects frequent version increments, this could avoid proliferating many functions. However, it slightly complicates testing and might introduce latency (though minimal).
A complementary approach is database schema versioning for the underlying data: as noted in Supabase discussions, one can create schema “v1”, “v2” etc., each exposing SQL views or RPC functions, and direct the Edge Function to call into the appropriate schema. This ensures data shape changes are isolated. Supabase’s PostgREST can even swap schemas per request, although for Parker it might be simpler to handle versioning at the function layer.
Recommendation: For Parker’s near-term needs, adopting function name versioning is likely sufficient and clear. The migration steps would be: (1) Duplicate the existing secure-traveler-profiles code to a new function (say profiles_v2) and implement the desired breaking changes (e.g. new request/response format). (2) Deploy profiles_v2 in parallel with v1. (3) Update the frontend (travelerProfileService.ts) to point to the new function for all calls, ideally gating this by a feature flag for a rollout (so you can switch specific users to v2 gradually). (4) Maintain secure-traveler-profiles (v1) for backward compatibility until no longer needed.
It's vital to also version the API documentation and client libraries accordingly. The Edge Function URL already includes “v1”, but that is Supabase’s static version. Parker should treat the function name or payload schema as the version identifier. In summary, versioning is a best practice to enable iterative improvements. By implementing a clear versioning scheme now (pre-GA), Parker avoids future breaking changes for clients.
B.2 Phone Verification: Twilio Webhook vs Client Callback
Current approach: Parker uses Twilio Verify via an Edge Function (send-sms-notification) and a React component PhoneNumberSetup.tsx where the user enters the code to verify. The verification result is handled via a client callback (the frontend calls the backend to check the code). There’s an open question about using Twilio’s webhook events to automate phone verification updates.
Trade-offs: Using explicit client callbacks (the status quo) means the app directly calls Twilio’s Verify API to check the code when the user inputs it. This yields immediate, synchronous feedback to the user (e.g. “Code verified” or an error if incorrect) and is straightforward to implement. It keeps the verification flow in-app and real-time – the user clicks submit and our server confirms the code within the same request cycle. This approach is typically low-latency (network calls to Twilio are fast) and keeps control within Parker’s logic (we can decide what to do on success, e.g. update phone_verified field).
On the other hand, Twilio Verify webhooks (status callbacks) can send an asynchronous notification to Parker when certain events occur (e.g. verification succeeded or failed). Twilio’s Verify Events system can push a “verification.approved” event to a webhook endpoint in our system. The advantage is that this can serve as a secondary confirmation or audit log – even if the user’s app closed, our backend would eventually get the result. Twilio’s docs note that event streams can notify within seconds as well. However, relying solely on webhooks for the user-facing flow has downsides in latency and complexity. There is inherently a bit more latency: Twilio must call our webhook, and we’d then have to update the user’s profile and somehow inform the client (which likely means the client polling or using a real-time channel). This is less real-time from the user’s perspective compared to a direct verify call.
Reliability & security: Webhooks introduce an additional point of failure – our endpoint must be up and secure (validating Twilio’s signature on incoming requests to avoid spoofing). If our service is briefly down or the network blips, we might miss a callback (Twilio will retry, but still). With client-initiated verification, we control the flow and can handle errors immediately (prompt user to retry code, etc.). Security-wise, using our backend to verify means the verification code travels through our server to Twilio, which is fine since it’s transient. With webhooks, we’d be storing the phone number and code status in Twilio and trusting Twilio to notify us – still secure if configured correctly, but an extra integration point to monitor.
Recommended approach: Continue using explicit client/backend verification calls for the primary user flow, as it provides a faster and more interactive UX. The Parker app should keep doing what it does: user enters 6-digit code, our Edge Function (via supabase.functions.invoke) calls Twilio’s Verify Check API and returns success or failure immediately. This ensures the user instantly knows the result and we can update the UI (and profiles.phone_verified) in real time.
However, Parker can augment this by subscribing to Twilio’s Verify Events webhook for backup logging or analytics. For example, Twilio can send a verification.approved event with details like timestamp and phone country code, which we could use to log verification attempts. This would be Phase 2: set up a secure webhook endpoint (maybe another Edge Function) to handle Twilio callbacks, and use it to double-confirm marking the user verified in the database (idempotently) and record metrics (like how many attempts each user needed – which could feed into a risk engine).
In summary, client callbacks offer better immediacy and control for the user flow, while webhooks are useful for out-of-band updates or fail-safe processing. The trade-off in latency and complexity doesn’t favor using webhooks as the sole mechanism for a user-facing verification step. Parker should stick to the current method (which is working), and possibly implement the webhook as a background enhancement. As part of this, ensure to handle edge cases: if a verification code expires or max attempts reached, Twilio’s events like verification.max_attempts_reached can inform us, allowing Parker to prompt the user appropriately (e.g. send a new code).
Finally, whichever approach, document the flow clearly. The developer guide indicates uncertainty on whether a Twilio webhook auto-updates phone_verified. We clarify: Twilio will not update our Supabase DB by itself – we must update it either in the synchronous verify response handler or in a webhook handler. Thus, we will explicitly set phone_verified=true in our code upon successful code check (and perhaps double-check via webhook event). This gives us a robust, low-latency verification system with audit trail.
B.3 Stripe Payment Methods – Deletion Workflow
Parker currently tokenizes and saves cards via Stripe SetupIntents (off-session usage). The open questions are: when a user deletes a payment method in our app, do we also call Stripe to detach that card, and what about orphaned Stripe Customer objects?
Best practice: Yes – when a user removes a saved card, we should detach the PaymentMethod from the Stripe customer to ensure it’s fully removed. Stripe’s API provides paymentMethods.detach("pm_xxx") which essentially “unlinks” the card from the customer record. Once detached, the card can’t be charged or reused unless added again, effectively acting like a deletion. This is important for security and cleanliness: users expect that deleting a card in Parker means it’s gone from our systems entirely. Detaching in Stripe fulfills that expectation (Stripe will still keep some record internally for compliance, but it’s no longer associated with the user’s account).
The Parker dev guide notes uncertainty about this, with a code comment asking “Do we also need to detach from Stripe?”. The answer is yes, we should. Relying solely on deleting the record in our database is not enough – otherwise, the card remains in Stripe’s vault linked to the customer, which could become an orphaned PaymentMethod if not tracked. By detaching, we prevent accumulating unused cards on Stripe’s side.
Regarding orphaned Stripe customers: if a user deletes their Parker account (or all payment methods), we might consider deleting the Stripe Customer as well. Stripe Customers with no attached payment methods and no charges are essentially unused. Removing them can reduce clutter and avoid hitting limits (Stripe doesn’t hard-limit customers, but cleaning up is good practice if compliant with record-keeping requirements). However, if the user had any transactions, we might keep the customer for record (to preserve charge history in Stripe). Stripe doesn’t automatically delete customers – this is a decision for Parker. Many systems choose to keep the customer record even if empty, for potential future use or auditing. But Parker could implement an orphan cleanup job: e.g. a cron that deletes Stripe customers that meet criteria (no payment methods, no charges, and perhaps account deleted on our side). Stripe’s API allows customer deletion, which removes personal data (useful for GDPR “right to erasure”) – note this is irreversible.
Comparison – SetupIntent vs detach: The SetupIntent is used at card addition time to securely collect and attach a PaymentMethod to a Customer. It’s not directly related to deletion except that using SetupIntents means the card is definitely attached to a Customer (we have that customer ID stored). Therefore, to remove that card, PaymentMethod.detach is the correct counterpart. There’s no “delete” method on SetupIntent – SetupIntents are one-time objects to set up the payment method. After that, the PaymentMethod object persists until detached. So the proper Stripe workflow is: attach via SetupIntent, store stripe_pm_id and stripe_customer_id in our DB, and on removal, call stripe.paymentMethods.detach(stripe_pm_id). This ensures the PaymentMethod is not usable. As a further step, if we know the user is gone entirely, we might call stripe.customers.del(customerId) to delete the customer.
Migration steps: Parker should update the Edge Function that handles payment method deletion to include a call to Stripe. The dev guide shows a stub for this. We will implement:
js
Copy
// Pseudocode for deletePaymentMethod function
await deletePaymentMethodFromDB(id);  // existing
if (stripePaymentMethodId) {
    await stripe.paymentMethods.detach(stripePaymentMethodId);
}

Additionally, define a policy for Stripe customers. Perhaps: if a user deletes their account or all cards, and had no successful charges, delete the customer. Otherwise, keep the customer (since it may have associated charges or invoices). Stripe’s own docs and community suggest detaching cards is essentially the same as deleting them from user perspective – indeed re-adding the same card later will create a new PaymentMethod object.
By doing this, Parker avoids stale data in Stripe and fulfills GDPR obligations to not retain unneeded personal data. It also prevents issues where a card might still be chargeable via Stripe console – detaching it locks it down.
In summary: Use SetupIntent for adding (already done), and use PaymentMethod.detach for removal – they are complementary parts of the card lifecycle. Ensure our code reflects that and that we document this in the developer guide (the guide currently flags this as a decision needed, so we now resolve that decision).
B.4 Feature Flags: LaunchDarkly vs Split vs Home-grown
Context: Parker is introducing new profile features (like the tabbed layout) and wants the ability to gate these via feature flags. Currently no framework is implemented. We need to choose between managed services (LaunchDarkly, Split.io) or building our own toggle system.
Developer Experience & Power: LaunchDarkly is widely regarded as the industry leader, offering a robust, developer-friendly platform. It supports unlimited custom user attributes for targeting, multi-variate flags, experimentation, and has an easy SDK for React (with hooks). As one software buyer noted, “LaunchDarkly wins hands-down… easy to use, scalable, reliable, constantly improving”. It provides real-time flag updates (via streaming), meaning we can toggle a flag in the LD dashboard and users’ apps update immediately without reload. It also integrates with project management (to track flag status) and has an analytics dashboard to see flag usage.
Split.io is another strong contender, with a focus on experimentation analytics. It offers the core flagging capabilities and additionally built-in A/B test metrics (like measuring impact of a new feature on conversion). If Parker’s primary goal is data-driven rollout (which might be relevant as we introduce profile completion scoring, etc.), Split’s advantage is its emphasis on statistically robust experiments. However, some sources note that Split’s pricing can be higher and it may not support as many kinds of custom contexts per flag as LaunchDarkly. LaunchDarkly allows complex targeting rules (by user, group, device, etc.) without limit, whereas Split might be slightly more rigid there.
Cost considerations: Neither LaunchDarkly nor Split are cheap for large user bases. LaunchDarkly charges per seat (team members) and volume of flags/users – companies at scale have reported spending hundreds of thousands per year. Split’s pricing is also enterprise-grade (and one analysis claims Split is more expensive than LaunchDarkly for teams of all sizes, contrary to what one might assume). For a startup or mid-size service like Parker, cost is a concern. Home-grown solution (or open-source like Unleash) could save money but at the cost of engineering effort and fewer features. Unleash, for instance, is open-source and can be self-hosted; it provides basic flag targeting but lacks the polish and some advanced targeting of LD/Split.
Targeting & scale: LaunchDarkly excels in fine-grained targeting – you can roll out a feature to, say, 10% of new users in Canada easily. It also guarantees low-latency evaluation (SDKs evaluate flags in-memory based on a streaming feed of changes). Split also has targeting and an SDK, and focuses on ensuring experimentation rigor (it can track metrics and do significance testing). If Parker values an integrated experimentation platform, Split might be appealing; if the priority is quick implementation and broad community support, LaunchDarkly is safer.
Recommendation: Adopt LaunchDarkly for Parker’s feature flag needs. As the Reddit review summarized, it’s the best-of-breed and suitable for any size company due to ease of use and reliability. Parker’s team can implement it quickly using the React SDK (launchdarkly-react-client-sdk) as illustrated in the developer guide snippet. LaunchDarkly will let Parker turn on the new Profile tabs for internal testing (S-1, S-2, etc.) and gradually rollout to beta users, then all users with a simple config change – all without redeploying code. The migration steps are straightforward:
Sign up for a LaunchDarkly account (they have a free tier for a small number of users/flags which might cover dev/staging).


Include the LaunchDarkly client in the frontend, initialize with the environment SDK key. Use a consistent user key (probably the Supabase user.id) for flag targeting.


Wrap new features (e.g. the “Traveler Info” tab) in conditionals checking the LD flag. For example: const { showNewProfileTab } = useFlags(); if(showNewProfileTab) { ...render new tab... }.


For critical backend differences, one can also use LaunchDarkly’s server SDK in Edge Functions (or use environment variables toggled via Supabase config as a simpler home-grown toggle for backend logic if needed).


Gradually enable the flag in LaunchDarkly’s dashboard: first to internal users (perhaps by email domain), then a percentage rollout, then 100%.


This approach gives Parker full control and the ability to rollback instantly if something goes wrong, which is invaluable during the phased rollout of a major profile redesign.
We considered a home-grown solution (like a flags table in the database or an open-source library). While cheaper, maintaining it (especially for real-time updates and user-targeting) can become a significant project. Parker’s roadmap is aggressive, so leveraging a proven platform saves time. The risk of vendor lock-in is acknowledged (migrating off LaunchDarkly later would require work), but the immediate benefit of rapid, reliable flagging outweighs that for the next couple of years.
In summary, use LaunchDarkly for its superior developer experience and strong feature set. Keep Split as a consideration if in the future Parker specifically wants built-in experiment analysis on feature outcomes (we could feed event data to Split). For now, LaunchDarkly’s own experimentation add-on or just using it for controlled rollouts plus analyzing metrics via our analytics pipeline (see next section) should suffice. Document the chosen approach so all developers use the flags consistently (the snippet in our guide already shows how each option’s code would look).
B.5 Analytics Pipeline: Snowplow vs Segment for Profile Events
Parker plans to emit events like profile_score_updated when users update their profile. The decision is between Snowplow (an open-source, warehouse-first event pipeline) and Segment (a cloud Customer Data Platform).
Real-time and warehouse integration: Snowplow is known for its real-time event stream capabilities and for delivering data directly to your storage (data warehouse) in a structured format. Snowplow can get event data into a warehouse in as little as 5 seconds, enabling near real-time analytics or personalization. It also uses JSON schemas to validate events for quality control – meaning Parker can define a schema for profile_score_updated and be confident all events conform, which reduces garbage data. Snowplow is essentially a build-your-own Segment with full ownership: you deploy collectors and processors (e.g. on AWS or GCP) and data lands in your database under your controlsnowplow.io. This aligns with a “warehouse-first” philosophy – good for Parker if we have a strong data engineering team and want complete control over our event data (for AI, BI, etc.). It’s also potentially more cost-efficient at scale since it’s open-source (though hosted options exist).
Segment, on the other hand, shines in ease of use and breadth of integrations. With Segment, you instrument events in the app and Segment will forward those events to many possible destinations – data warehouses, but also marketing tools, analytics SaaS (Mixpanel, Google Analytics), etc. Segment is a managed service; its strength is out-of-the-box connectors (if Parker wants to send profile events to both our warehouse and say, Intercom or Braze for user engagement, Segment can do that with a flip of a switch). However, Segment’s real-time ability is somewhat limited for warehouse ingestion – often data might flow in batches or with noticeable latency (potentially minutes, sometimes hours depending on the plan and destination). According to Snowplow’s comparison, Segment cannot support sub-5-second latency the way Snowplow can for streaming use cases. If Parker envisions, for example, showing a user their profile completion score update in real-time from an analytics computation, Snowplow’s streaming could facilitate that, whereas Segment would treat the warehouse as an eventually-consistent sink.
Data ownership and privacy: With Snowplow, Parker hosts the pipeline, so all data stays in our cloud (we own it)snowplow.io. With Segment, the data first goes to Segment’s cloud (they store it, then relay), raising potential compliance considerationssnowplow.io. Given Parker deals with personal profile data, a Snowplow setup could better ensure GDPR compliance by keeping raw data in-house and avoiding third-party storagesnowplow.io. Segment acts as a data controller in GDPR terms, so we’d need a DPA with them.
Cost: Segment is typically priced per monthly tracked user or events volume, and it can get expensive if Parker has lots of events. Snowplow, being self-hosted, costs mainly cloud infrastructure and maintenance time. If Parker already has a modern data stack (Kafka or Kinesis, a data lake or warehouse), Snowplow might integrate nicely. If not, Segment might be faster to get started (no infrastructure to maintain).
Developer effort: Implementing profile events with Segment is very simple – use their SDK or HTTP API to send events, and Segment takes care of the rest (including retrying, etc.). Implementing Snowplow requires deploying collectors (e.g. a cloud function or container to collect events) and an enrichment pipeline. There are now hosted Snowplow options (Snowplow BDP Cloud), but as of 2025 those may be in early stages. Parker could also consider RudderStack (an open-source Segment alternative, which bridges some gap by providing a warehouse-first approach but with easier setup).
Recommendation: Snowplow is recommended if Parker has the engineering resources to set it up, because it aligns with our warehouse-first, real-time needs and avoids vendor lock-in. We can instrument events (like profile_score_updated) using Snowplow’s tracker libraries (they have a JavaScript and possibly a React tracker) and events will flow into, say, our Snowflake or BigQuery in near real-time. Snowplow’s ability to enforce schemas means our ProfileScoreUpdatedEvent will always have the expected fields, preventing junk data. This is valuable as Parker’s profile system grows (we can evolve the schema with versioned schemas, ensuring backward compatibility on analytics). Also, Snowplow is built to handle high event volumes reliably since it’s essentially our own pipeline.
If Parker’s team, however, is small and cannot manage an event pipeline, then Segment is a viable alternative to get started quickly. Segment will let us send profile_score_updated events to both our warehouse and any other tools we might adopt (like Amplitude for product analytics or Braze for messaging) with minimal fuss. The downside is cost and less control over data quality.
Given Parker’s emphasis on being future-proof and possibly wanting to own data (not to mention no analytics events are implemented yet, so we can choose a fresh path), I lean toward Snowplow. We should weigh that Snowplow requires an initial setup: deploying their collector (could be as simple as using a CloudFront collector endpoint and a Lambda for enrichment if using their serverless mode). But numerous companies have shown Snowplow can scale and provide 5-second latency to warehouse, which is impressive. And with our own warehouse, we can directly query events or join them with operational data for rich insights (the composable CDP approach).
Migration/implementation steps for Snowplow:
Deploy Snowplow mini or open-source pipeline in our cloud (there are quickstart Terraform scripts).


Add Snowplow tracker to the frontend. When profile completeness changes or other profile events occur, call trackSelfDescribingEvent with our predefined schema (as shown in the guide snippet for Snowplow usage).


Set up the data warehouse integration (Snowplow can directly insert into Postgres or BigQuery/Snowflake via streams).


Validate events in the warehouse and build a simple dashboard to monitor profile_score_updated trends.


Segment implementation steps (if chosen):
Sign up for Segment, get a write key.


Use Segment’s JS snippet or React SDK to analytics.track("Profile Score Updated", {...properties}) with the relevant data.


Configure Segment to forward to our data warehouse (and any other tools needed).


Verify data flows into the warehouse.


We must also consider data governance: Segment by default doesn’t enforce a schema; we’d rely on conventions. Snowplow’s schema enforcement is a plus for governance. Parker’s data is sensitive, so having a clear contract for events is beneficial.
In conclusion, Snowplow is ideal for a warehouse-centric, real-time pipeline (with events under our control and possibly usable for real-time features down the road), whereas Segment offers expediency and multi-destination flexibility. Given Parker’s tech-forward approach and desire to be “warehouse-first” and privacy-conscious, I recommend Snowplow as the primary choice, with a note that it requires more setup. If quick value and less dev effort is needed, Segment could be used initially then phased out later (some companies start with Segment and later migrate to Snowplow or RudderStack to cut costs and gain control).
Either way, instrument the key events (profile created, completed, score updated, etc.) early so we collect valuable data from day one of the new profile system. Ensure that events like profile_score_updated include relevant properties (user_id, old_score, new_score, factors, timestamp as outlined) and do not include PII unnecessarily to avoid privacy issues. By Phase 3, Parker will have an analytics pipeline emitting events on profile changes, which can feed into personalization (e.g. sending an email via Resend when profile hits 100% – triggered via these events).
Track C – Future-Proofing & Expansion
C.1 Multi-Traveler Profiles & Group Bookings
As Parker expands, the profile system must support multiple travelers per account and group travel scenarios. Currently, each user has one primary profile plus maybe separate traveler entries, but it’s not truly multi-profile friendly (no UI to manage family members, etc.). Best practices from airline and booking platforms show a clear path: implement a “Saved Travelers” or “Travel Companions” feature in the account. For example, American Airlines allows users to add family member details under “Reservation preferences > Add travel companions” – so when booking, they can select pre-saved companions instead of retyping info. United’s app similarly enables storing companions and even sharing boarding passes among a group on one device.
Schema recommendations: We should allow a one-to-many relationship: a single Parker user can have multiple Traveler Profiles (which we already have as a table) that represent different people. In Parker’s DB, this likely means the traveler_profiles table’s user_id foreign key can link multiple rows to the same auth.users.id (the owner account). This seems to already be the case (the system has traveler_profiles separate from profiles) but might need adjustments to clearly flag which traveler is the main account holder vs an added companion. We might add a field like owner_user_id and traveler_name etc., or use the existing structure but expose it better. The architecture plan explicitly lists “Allow multiple traveler profiles per user” and “Implement family booking workflows” as goals, so the groundwork is there.
UI patterns: A tab or section in the profile labeled “Travelers” or “Family & Friends” would let users manage these profiles. This could be a simple list: “John Doe (Self), Jane Doe (Spouse), Junior Doe (Child)” with options to add, edit, or remove. Many travel sites implement an “Add New Traveler” form that collects the typical info (name, DOB, passport, etc.) and saves it. Airbnb has something conceptually similar with its guest invitation system, and Expedia and Booking.com allow saving traveler details in your account for reuse.
For group bookings, the system needs to handle selecting multiple traveler profiles during a booking flow. Pattern: when a user initiates a booking for 4 people, they can choose from their saved travelers for each passenger slot or enter new info. To support that, our profile system should expose traveler profiles via API so the booking system can fetch them. The auto-booking flow already hints at reusable traveler data, which is great. We should ensure traveler profiles include all fields needed for booking (passport, loyalty numbers, etc.) and are linked to the booking records when used.
Sharing and permissions: Parker might consider if traveler profiles can be shared between accounts (e.g. a spouse has their own Parker account but you want to add them as a traveler in your profile). This can get complex (it’s essentially linking two users’ profiles). A simpler initial approach is each traveler profile is purely owned by one user (you can add your family members who don’t have their own login). The architecture doc does mention “traveler profile sharing permissions” as a future item, which suggests eventually we might allow cross-account sharing (like a family account). For now, focusing on basic multi-traveler support is priority.
Group bookings also entail UI to handle group communication and notifications. We should plan that if a booking has multiple travelers (some of whom have their own Parker accounts), how do notifications go out? Possibly send to the primary booker or to each traveler if they are users and have preferences. For now, assume one user is the owner of the booking and thus gets notifications for all.
Implementing multi-traveler profiles will significantly enhance user experience: Frequent bookers (e.g. executive assistants booking for others, or parents booking for children) will save time and avoid data re-entry. This was highlighted in user feedback on airline forums: people are “tired of constantly typing their family’s details” and rejoice when an airline (like AA) provides a companion-saving feature. Parker can gain a competitive UX edge by matching this convenience.
Design considerations: In the profile UI, indicate clearly which saved traveler is “You” (the account owner) and which are others. Perhaps allow labeling (e.g. “Jane Doe – Daughter”). Use icons or avatars to differentiate. When editing a traveler, if it’s the user themselves, some fields (email, etc.) might be tied to the main account; for companions, all fields are editable. Also, implement validation and completeness for traveler profiles too – maybe show a completeness meter for each traveler profile to encourage filling out all details (especially if Parker will use this for seamless booking).
On the backend, enforce that users can only access their own traveler profiles (RLS policies already cover that for user_id matching). If sharing comes later, we’ll extend permissions accordingly (maybe via a linking table of authorized user_id for a traveler_id).
C.2 Omni-Channel Notifications & User Preferences
Future notifications will span email, SMS, push, and in-app channels. Parker should implement an omni-channel notification system where users can choose how (and when) they receive different types of messages. Building on Track A’s discussion of preferences, future-proofing means supporting new channels (e.g. mobile push if Parker launches a mobile app, or WhatsApp perhaps) and more granular controls like quiet hours and digest frequency.
Omni-channel architecture: Likely Parker will integrate providers like Twilio (for SMS/WhatsApp), Resend or SendGrid (for email), perhaps Firebase or OneSignal (for push notifications). The profile schema can store preferences as a JSON or structured table that captures, per notification category, the preferred channel(s). Indeed, Parker already stores notification_preferences as JSONB; we’ll extend that to include push and perhaps in-app. For example, a user might set flight_reminders: { email: false, sms: true, push: true, in_app: true }. The notification service (perhaps via Supabase Edge Function or external job) would then fan out the message to the enabled channels.
User-defined quiet hours: This feature is increasingly expected. Slack and mobile OS have conditioned users to want control of when they are interrupted. Implementation-wise, Parker can allow each user to set a daily “Do not disturb” window (local time or specified timezone). We store, e.g., quiet_hours: { start: "22:00", end: "07:00", timezone: "America/Chicago" } in the profile. Our notification sending logic then checks before sending an SMS/push: if current time falls in the user’s quiet window, defer the notification (or send it to a quieter channel like just email, or queue it for later). For emails, which are less intrusive, quiet hours might not matter as much, but we should consider it for SMS and push. Many marketing systems enforce quiet hours to avoid sending texts at night. We should also possibly present an option like “Snooze all notifications until [date]” if a user goes on vacation – but that can be later; quiet hours covers the daily cycle.
Digest frequency: Provide choices like Immediate, Daily Digest, Weekly Digest for certain notification types. For instance, promotional fare alerts could be grouped into a weekly summary instead of immediate pushes, if the user prefers. Quora’s example was instructive: not everyone wants instant pings for recommendations; a summary is better. Implementing digests means Parker needs a batching mechanism: e.g., collect all notifications of type X for user Y, and at 8am each day send one email containing all. This likely requires storing pending notifications and a cron job or scheduled function. It’s more involved, but doable with a task queue or even in-database scheduling.
From a UX perspective, combining these preferences needs careful UI design to avoid confusion. A likely approach: in the Notifications settings UI, under each category, let the user toggle on/off each channel (as we do now), and additionally have a section for global settings like Quiet Hours (with time pickers) and Digest Setting (perhaps a dropdown: Real-time vs Daily vs Weekly for applicable categories). The SuprSend blog outlines exactly this kind of advanced preference center, including examples like Slack’s schedule and Quora’s digest setting. It even suggests allowing channel-specific frequency choices (e.g. real-time via in-app, but daily via email) – though that could get complex.
Internationalization of channels: Since Parker might operate globally, also consider localization of the content and channel availability. For example, in some regions WhatsApp notifications are preferred over SMS. Our system could be extensible to accommodate new channels (just add a field in preferences and integrate the API). Ensuring that templates for notifications are easily localizable (see next section on i18n) is also part of future-proofing – content should be in the user’s preferred language on each channel.
Compliance: Omni-channel systems must respect user consent on a per-channel basis due to regulations (e.g. users must opt-in for SMS in some jurisdictions, double-opt-in for email marketing in EU, etc.). Our preference center will serve as that consent record. We should log when a user enables/disables a channel for compliance audit. Also, implementing “unsubscribe” links in emails and STOP for SMS is necessary by law (CAN-SPAM, TCPA). If a user unsubscribes via an email link, it should update their profile preferences accordingly (perhaps via an API endpoint that doesn’t require login).
In summary, Parker should build a flexible notification service that checks user preferences (channel and schedule) before dispatching any notification. The groundwork in the current JSON preferences is good; we will extend it with new keys for push and quiet times. The UI will evolve to expose these in a user-friendly way (drawing inspiration from Slack, Teams, LinkedIn, etc., which all allow customizing when and how you get notified). This will ensure that as we add channels, users remain in control – a key expectation and a competitive advantage given how often users complain about notification overload. With these controls, Parker can proudly say we put users in the driver’s seat for communications, which also aligns with privacy regulations that emphasize user choice and consent.
C.3 Accessibility & Localization Standards for 2026+
To future-proof the platform, Parker must adhere to the latest accessibility (a11y) and localization (L10n) standards. By 2026, WCAG 2.2 AA will be the baseline standard to pass audits, with eyes on the upcoming WCAG 3.0. Additionally, laws like the ADA (Americans with Disabilities Act) and the European Accessibility Act will enforce these standards.
WCAG 2.2 (Level AA): WCAG 2.2 (published October 2023) added 9 new success criteria beyond WCAG 2.1. Parker’s UI/UX should be evaluated against these, as well as all existing criteria, to ensure compliance. Key new criteria in 2.2 AA include: Focus Not Obscured (making sure keyboard focus indicators are always visible, even if page elements scroll or overflow), Accessible Authentication (critical: login or verification processes should not rely on user memory or difficult tests – e.g. avoid only using CAPTCHA or security questions without alternatives), Dragging Movements (all functionalities that require drag-and-drop should have an alternate method) and Redundant Entry (users shouldn’t have to re-enter info that’s already provided, especially during multi-step processes). Parker’s progressive profile and booking flows must incorporate these: e.g., if a user has entered their address in profile, don’t force them to type it again for a payment form – that would violate the spirit of redundant entry criterion. Instead, autofill it or provide a one-click use of saved info.
We should also maintain a visible focus state on all interactive elements. Use high-contrast outlines for focused buttons/links so that keyboard and low-vision users can navigate. WCAG 2.2’s Focus Appearance (Enhanced) criteria even suggests specific thickness and contrast for focus indicators.
WCAG 2.2 AA is likely what audits will require through 2026 (indeed, new ADA rulings in the U.S. are set to require WCAG 2.1 AA by 2026, and forward-looking organizations are targeting 2.2). For Parker, achieving 2.2 AA means all standard things: ensure text has sufficient contrast ratio (4.5:1 for body text), provide text alternatives for images (alt tags), make all functions available via keyboard (no keyboard traps), provide captions/transcripts for multimedia, avoid content that flashes (to prevent seizures), and give users feedback and time control where needed. It also means implementing ARIA landmarks/roles in our React app (for example, marking the navigation, main content, forms, etc., properly so screen readers can skip to sections). Use semantic HTML or appropriate ARIA when needed (but don't overdo ARIA if not needed). We should test with screen readers (NVDA/JAWS, VoiceOver) to ensure our forms (like profile forms) are announced properly (each field labeled, any errors reported clearly).
Localization (i18n) and RTL support: Parker should be built ready to support multiple languages and regions. This involves two aspects: technical i18n in the software, and design considerations for things like right-to-left (RTL) languages. To be 2026-proof, we should follow Unicode best practices and use i18n libraries (e.g., format.js or i18next) for all user-facing text. That means no hard-coded strings in the UI – instead, use translation files so adding a new language is straightforward. Also ensure date, time, number formats are locale-aware (e.g. using toLocaleString or libraries that use CLDR data).
For RTL support: The CSS and layout should accommodate mirroring. Using CSS logical properties (like margin-inline-start instead of margin-left) can ease this. Frameworks like shadcn/UI (Radix) likely have some support, but we must verify components behave under RTL (for example, carousels or icons might need flipping). We should also test bidi (bidirectional) text handling (mix of LTR and RTL in one sentence, etc., should render properly).
By 2026, WCAG 2.2 AA will definitely be expected, and WCAG 3.0 might be in late stages but not yet required (WCAG 3.0 “Silver” is a major rework, possibly a recommendation by 2026-2027). However, Parker can keep an eye on WCAG 3 drafts, which emphasize outcomes and user needs more than technical criteria. Regardless, if we meet 2.2 AA thoroughly, we’re in a strong position. We should also consider assistive technology trends: for example, ensure our components support accessible names and roles such that screen reader users can operate everything – e.g., our custom controls like a date picker for DOB should be announced properly and allow keyboard selection.
Another consideration: Accessible authentication – since Parker involves profile security, we should implement login/verification flows that have alternatives to memorization. WCAG 2.2’s new criterion on this means if we have a cognitive test (like “name your first car”), we must provide an alternative (or don’t use those tests). Using email/SMS one-time codes (which Parker does for phone verify) is good, but also ensure users can copy-paste the code easily and the input boxes are labeled.
Localization standards also include cultural appropriateness and translation processes. We should adopt a standard locale framework early. That also ties into accessibility: offering content in the user’s primary language is part of accessibility (for example, for our international users, English might be a barrier). If Parker plans to expand globally, aim for at least the major languages and ensure our design can handle text expansion (some languages may be 30% longer than English). Also design icons and graphics in a culturally neutral way or localize them if needed (e.g., different ID formats, address formats per country in the UI).
Testing and audit: Leading up to 2026, Parker should schedule regular accessibility audits (external if possible) to catch issues. Automated tools (like axe, Lighthouse) can help for many WCAG issues but not all; manual testing with actual users or experts is invaluable. Similarly, for localization/RTL, testing with native speakers and using pseudo-localization (garbling text or adding markers) can highlight where text isn’t being translated or layout breaks.
Compliance and legal: GDPR and California’s CPRA also intersect here – ensuring features for data deletion (right to erasure), and not just features but making sure the UI to request or perform those actions is accessible. Parker should document how a user can delete their data (which might be through contacting support or maybe a self-service). Under GDPR, providing data export is another thing – perhaps a future feature: “Download my profile data” as a simple JSON/CSV for the user, to stay ahead of compliance.
In summary, meeting WCAG 2.2 AA is non-negotiable for 2025-2026. Parker will implement design/code updates to satisfy all criteria (especially new ones like Focus and Redundant Entry which map directly to our profile flow). We’ll ensure keyboard navigability, screen reader semantics, sufficient contrast, and error prevention throughout. Simultaneously, we’ll build with globalization in mind – easily translatable UI, RTL layout capability, and respecting locale differences. This way, when Parker is ready to launch in new markets, we won’t need a ground-up rewrite – it will be about plugging in translation files and perhaps adjusting content to local travel norms. It also means in 2026, if an accessibility audit or legal compliance check happens (whether by a partner or government), Parker will pass with flying colors, having embraced these standards proactively.

Gap Analysis Matrix – Parker vs. Best Practices
The following table summarizes how Parker’s current implementation (as gleaned from the developer guide and architecture review) compares to industry best practices and recommendations across key areas:
Aspect
Parker Current Implementation
Best Practice / Industry Standard
Profile Completion Indicator
No profile completeness meter or gamification in UI (users receive no feedback on progress). Profile form is basic and not incentivized.
Use visual progress indicators (bars/rings) and milestones. E.g., LinkedIn-style “profile strength” meter. Gamify with badges or rewards for 100% completion. This guides users to fill missing info and acknowledges progress.
Progressive Onboarding
All profile data often collected in one go; no staged or contextual onboarding. Risk of overwhelming users or incomplete data.
Incremental, progressive disclosure onboarding. Start with minimal info (name/email), then prompt for more in context (e.g., before first booking ask for traveler details). Wise/Revolut gradually introduce steps to reduce cognitive load.
Data Collection Explanations
Lacks clear in-UI explanations of why certain data is asked (e.g., why passport or phone is needed). Users may not understand value of completing profile.
Trust-building copy accompanying fields. E.g., “Your phone is used for flight updates” or “Passport info needed for faster check-in”. Provide tooltips or notes highlighting security (lock icons, “we encrypt this data”) and convenience (autofill benefits).
Multiple Traveler Profiles
Each user has one traveler_profile. No UI to add additional travelers; limited support for family or group profiles (though backend has table for traveler_profiles).
Allow multiple saved travelers per user with full CRUD management. E.g., American Airlines “Add travel companions” feature. Schema supports one-to-many user->travelers, and UI list to manage family members. Facilitates group bookings and saves re-entering info.
Payment Method Deletion
Payment methods stored with Stripe SetupIntent, deletion in app only removes DB entry. Unclear if Stripe paymentMethod.detach is called. Orphaned Stripe customers not handled.
Detach payment methods in Stripe when user deletes a card. This ensures card is removed from Stripe’s vault (cannot be charged). Also implement strategy for orphan Stripe customers: if a user account is deleted (or no payment methods remain), consider deleting the Stripe Customer for GDPR compliance (if no prior transactions) or leave for record if needed. Clear up ambiguity by making backend perform Stripe cleanup on deletion.
Notification Preferences Granularity
Basic on/off toggles for a few categories, stored in JSON. No UI for quiet hours or digest; no channel-specific opt-outs (assumes email & SMS only).
Granular omni-channel prefs. Each notification type configurable per channel (email, SMS, push). Support user-set quiet hours (no notifications during 10pm–7am, for example) and digest options (e.g., daily summary vs immediate). Provide a friendly UI (Slack/LinkedIn style) for fine control, building trust and reducing notification fatigue.
API Versioning
Single version (/functions/v1/secure-traveler-profiles) in use. No strategy documented for introducing v2 without breaking changes; potential confusion around Supabase “v1” path.
Versioned API endpoints or routing. e.g., deploy /secure-traveler-profiles-v2 for next iteration, or embed version in request and route internally. Maintain old version until clients migrate. Also consider versioning DB schema via versioned views for backward compatibility. This prevents disruptions when API changes occur.
Feature Flag System
No feature flag framework; new features toggled via code changes. Dev guide considering LaunchDarkly/Split/home-grown.
Implement a feature flag service for controlled rollouts. LaunchDarkly recommended for full-featured targeting and ease. Allows gradual rollouts (percentages, segments) and quick rollback. Alternatives: Split.io (strong experimentation analytics) or open-source Unleash (cost-saving, but less robust). Best practice is to avoid home-grown unless very simple needs, due to maintenance and lack of targeting features.
Analytics Events Pipeline
No analytics events emitted yet for profile actions. Considering Snowplow vs Segment. No tracking of profile completion changes or user behavior in place.
Establish event tracking to inform product decisions and personalization. Snowplow offers real-time, rich event tracking to your own warehouse (5s latency) with full control over datasnowplow.io. Segment offers ease of integration and many destinations, though with potential latency and cost. Best practice is a warehouse-first approach: ensure all events (e.g. profile_score_updated, booking_made) land in a central analytics DB quickly. This allows building a 360° view and powering features like personalized recommendations. Also enforce schema for events (Snowplow’s approach) to maintain data quality.
Accessibility Compliance
Basic compliance likely (semantic HTML in React, use of Supabase UI components). But no explicit mention of WCAG audits or some known gaps: e.g., no evidence of focus indicators customization, or testing with screen readers. Some modals or custom inputs might lack ARIA tags (needs review).
WCAG 2.2 AA compliance across the app. Ensure all interactive components are keyboard-accessible and have visible focus. Add support for new criteria like “Accessible Authentication” (login/verifications without memory test) and “Redundant Entry” (don’t require re-entering data) – e.g., use saved profile data during checkout to avoid asking twice. Regular a11y audits and involving users with disabilities in testing. Aim for high contrast UI, proper labels, and error messages that are announced to assistive tech. By 2026, adhering to WCAG 2.2 AA is mandatory for many sectors. Parker should also keep an eye on WCAG 3.0 drafts to anticipate future changes (like more outcome-oriented metrics).
Localization & RTL Support
English-only interface currently. No indication of localization framework in code. Likely not yet optimized for other languages or RTL layouts.
Internationalization-ready UI. Use i18n libraries to externalize all strings, allowing translation. Design layouts to accommodate text expansion and different scripts. Implement RTL support (test screens by flipping to Arabic/Hebrew – ensure components mirror appropriately). By planning for localization now, Parker can expand globally without redesign. Also ensure formats (dates, numbers) localize and that locale-specific needs (e.g., name order, address format) can be handled. This also ties into accessibility – providing content in the user’s language is crucial. Standards: use UTF-8 everywhere, handle Unicode correctly, and follow locale-specific best practices (via CLDR data).

Table: Parker Flight’s current state vs. best-practice benchmarks (2023–2025) in UX, architecture, and compliance. Parker has a solid foundation (good security, modern tech), but needs UX enhancements (gamification, progressive onboarding) and engineering upgrades (feature flags, analytics, API versioning) to match top-tier products. The gaps identified above prioritize what to tackle first.
Recommended Architecture & Library Choices (Open Engineering Questions)
Based on the research and Parker’s context, here are concrete recommendations for the five key engineering decisions, including rationale and suggested migration steps:
Supabase Edge Function API Versioning – Decision: Version via distinct function names/endpoints.
 Recommendation: Adopt a URL-based versioning strategy by deploying new Edge Functions with versioned names (e.g. secure-traveler-profiles-v2). This is simpler than building a custom router and aligns with REST best practices (clear version in path). It avoids breaking existing clients while enabling iterative improvements. Supabase’s built-in /functions/v1 prefix is static, so we control versioning at the function name level.
 Rationale: Easiest to implement and communicate – clients explicitly call the v2 endpoint when ready. This approach was validated in community discussions, noting no native multi-version support, so separate functions or a proxy is needed. A proxy router adds complexity and slight latency, whereas separate functions keep concerns isolated.
 Migration Steps:


Copy current function code to a new function (update as needed for v2 changes).


Deploy secure-traveler-profiles-v2 alongside v1.


Update frontend to target v2 (perhaps behind a feature flag to switch for testing).


Monitor calls to v1 vs v2 – once all active clients use v2, deprecate v1.


Document the changes in API docs (if public API).
 Over time, if more versions are needed, consider refactoring common logic into shared modules to avoid code duplication across versions.


Twilio Verify: Webhook vs Client Callback – Decision: Continue using explicit client→server callback for verification, and add webhook for redundancy if needed.
 Recommendation: Client-side verification flow remains primary – the frontend collects the code and our backend calls Twilio’s Verify API to check it. This provides immediate feedback to users. Implement Twilio’s Verify Events webhook as a supplemental listener for verification status updates (to log events or handle edge cases like a code verified after user closed the app).
 Rationale: The client-driven approach yields low latency and straightforward UX – user clicks “Verify” and gets result in the same session. Relying solely on Twilio’s webhook would introduce unnecessary delay and complexity (need to poll or push status to client). By keeping the verification synchronous, we maintain a reliable user experience. Twilio’s webhook can still be leveraged for audit trails or to auto-update the profile if a code is verified out-of-band, but it shouldn’t be the only mechanism for a real-time action. Additionally, using webhooks requires careful security (validate Twilio signatures) and retry logic – acceptable for background processes but not ideal for front-end interactivity.
 Migration Steps:


Continue with current implementation for entering and verifying codes (no action needed for core flow). Ensure the backend sets phone_verified=true immediately on successful code check.


Configure a Twilio Verify Event Stream webhook URL (e.g., a new Edge Function /verify-callback). In that function, validate request signature and update the user’s phone_verified status if not already, and log verification events (for analytics or security log).


Test webhook reception (Twilio allows test events) to confirm our system handles them idempotently.
 This hybrid approach covers both interactive needs and robust backend consistency.


Stripe Payment Method Removal & Orphan Cleanup – Decision: Detach payment methods via Stripe API on deletion, and schedule Stripe Customer deletion for truly orphaned accounts.
 Recommendation: Integrate Stripe’s paymentMethods.detach in the wallet removal flow. When a user deletes a saved card, our Edge Function should call stripe.paymentMethods.detach(pm_id). Additionally, implement a routine to delete Stripe Customer objects that are no longer needed: for example, if a user account is deleted or if a user has no payment methods and no recent activity, call stripe.customers.del(customerId). This could be a scheduled job that checks for orphaned customers.
 Rationale: Detaching ensures consistency between Parker DB and Stripe – no stale payment tokens remain. This is effectively “deleting” the card as far as the user and our app are concerned. It’s a best practice to minimize stored sensitive data, even if tokenized, and it avoids unexpected charges or errors (Stripe will error if we try to use a detached PM, which is good). Cleaning up customers aligns with GDPR “data minimization” – keep data only as long as necessarysnowplow.io. If a Parker user never actually made a booking (i.e., no Stripe charges), keeping their empty customer record in Stripe has no benefit. Removing it upon account deletion honors the user’s right to erasure. Stripe’s docs allow customer deletion; we should only do it after ensuring we don’t need that record for refunds or audits.
 Migration Steps:


Modify the deletePaymentMethod logic in our Edge Function: after removing the DB entry, call stripe.paymentMethods.detach(stripe_pm_id). Use Stripe’s Node SDK (with our secret key) to do this. Handle errors (e.g., if already detached or network issue) gracefully – possibly log and alert devs if detach fails, since we don’t want ghost cards.


Add unit tests or integration tests: create a dummy Stripe customer + card, run our deletion function, then check via Stripe API that the PaymentMethod’s customer field is null (detached).


For orphan customers: implement a small script or use Stripe’s API list capabilities. For instance, list customers with a certain metadata (we might tag Parker customers with metadata: { parkerUserId: ___ }). Identify those with no payment methods and no charges (Stripe provides fields like invoice_count or we’d have to list charges). We can run this monthly or trigger upon user deletion. Then call stripe.customers.del for each.


Ensure to not delete customers that have historical transactions because those are needed for receipts/refunds. For those, perhaps instead anonymize metadata if required.
 Document this behavior so support knows that deleting a Parker account also zaps their Stripe data unless transactions exist.


Feature Flags Framework – Decision: Use LaunchDarkly as the feature flag service for Parker’s platform.
 Recommendation: Integrate LaunchDarkly’s SDK for both frontend (React) and any Node backend portions (if needed), and manage feature toggles through LaunchDarkly’s dashboard. Set up flags for major upcoming features (e.g., new_profile_tabs, multi_traveler_enabled) and use LD’s targeting rules for gradual rollout.
 Rationale: LaunchDarkly provides a mature, reliable solution with rich targeting (by user attributes, segments, etc.) and real-time flag updates. This will let Parker deploy features dark and enable them for internal QA, beta users, or a percentage of traffic easily. The alternative, Split, is also capable, but considering the feedback that LaunchDarkly is best-in-class for general feature flagging and the likely similar cost brackets, LaunchDarkly is the safer choice. A home-grown solution would lack these capabilities and require maintenance; given Parker’s small team, using a proven service avoids reinventing the wheel and potential bugs in critical gating logic. LaunchDarkly also has a free tier (for up to a certain number of users or flags), which might cover Parker in early stages.
 Migration Steps:


Sign up for LaunchDarkly and obtain client-side SDK key for our environment.


Install launchdarkly-react-client-sdk. Wrap our app in <LDProvider clientSideID="sdk-123"> and use the useFlags or useLDClient hook where needed. For example, in our account profile page component, wrap new sections in conditionals: {showMultiTraveler && <NewTravelerSection/>}.


For backend (Supabase Edge Functions), if any functionality needs gating (less likely, but e.g., whether to execute certain logic), we could call LaunchDarkly’s server SDK. However, often we can funnel flags via frontend API calls (the frontend passes a parameter if a feature is on).


Create flags in LD UI (with descriptions so everyone knows what they do). Set default off (false) in production. Target Parker staff users (maybe by email domain) to true for testing.


Gradually update the flag rules to expand rollout: e.g., 10% of random users to true, then 50%, then 100%. LaunchDarkly will handle the bucketing consistently. Monitor system stability and user feedback at each stage.


When fully launched, either retire the flag (mark as permanently on) or keep it if we think we might toggle it again. LaunchDarkly allows flag cleanup to avoid clutter.


Ensure all developers are trained to use the flags and not rely on env toggles or manual config, to maintain consistency.


(If cost becomes an issue at scale, we can re-evaluate with an open-source alternative or bring it in-house, but that’s likely post-IPO level per the Reddit comments on cost.)


This approach will significantly de-risk deployments – we can ship code to production off (hidden behind flags), then turn it on gradually.


Analytics: Snowplow vs Segment – Decision: Implement Snowplow for event analytics, leveraging its real-time, warehouse-first design. Use Segment only if rapid multi-integration is needed, but current recommendation is Snowplow for Parker’s data strategy.
 Recommendation: Deploy Snowplow Open Source pipeline (or use a managed Snowplow service) to start capturing key profile events (profile_created, profile_score_updated, etc.). All events will stream into Parker’s own data warehouse (e.g., we can use BigQuery since Supabase is on Postgres for prod data – having an analytics warehouse is advisable to not mix analytical load on the primary DB). Design event schemas using Snowplow’s self-describing JSON schemas for consistency. If needed, use Segment for routing certain events to third-party tools (e.g., if marketing needs data in Braze or similar), but the core pipeline should be Snowplow to our warehouse.
 Rationale: Snowplow provides real-time data with full ownership – aligning with Parker’s likely needs for quick insights (e.g., to measure profile completion rates, or trigger in-app prompts immediately after an event). Snowplow’s guarantee of data quality via schemas ensures we maintain clean event data. This “warehouse-first” approach is more future-proof for advanced analytics and AI applications (we can feed the event data into ML models without third-party dependencies). Segment, while easier to start, would introduce a third-party holding our user event data and could delay warehouse syncing; also it’s an additional cost that might not be justified if Parker primarily wants data internallysnowplow.io. Many companies that care about data fidelity choose Snowplow or similar (or migrate off Segment as they scale). Parker can save long-term costs and avoid vendor lock by starting with Snowplow.
 Migration Steps:


Set up infrastructure: For an MVP, we could use Snowplow’s lightweight pipeline (they have quickstart for GCP/AWS). For example, deploy a Snowplow collector (could be a simple Cloud Function or Docker container) and a Snowplow enrichment + loader that writes to BigQuery or Snowflake. This requires some DevOps, but Snowplow provides terraform modules and good docs. Alternatively, use Snowplow’s managed trial to get started quickly, then migrate on-prem later.


Event design: Define which events to track. The guide gave a ProfileScoreUpdatedEvent schema – create a corresponding JSON schema (IGLU format) for it and host it (Snowplow needs a schema registry, which can be a static S3 or GitHub pages). Include fields like user_id, profile_id, old_score, new_score, completeness, verification_status, etc.. Do similar for other events like profile_created, traveler_added, etc.


Integrate tracker: Add Snowplow’s JavaScript tracker to the web app (it’s a small script that can batch events). Use it to send events at appropriate times, e.g., after a profile update completes, call trackSelfDescribingEvent(profileScoreEvent). Ensure user identity is passed to Snowplow (likely by setting the user_id as the domainUserId or as a custom context so events can be tied together). Also consider adding a consent mechanism if required (users can opt out of tracking – for privacy compliance, though for essential events we might deem it necessary for service).


Warehouse and analysis: Set up a data warehouse if not already (could be Supabase’s analytic schema, but better a separate analytics DB for scale). Snowplow will populate events there. Verify that events show up (within seconds).


Use SQL or a BI tool to analyze: e.g., what’s the average profile completeness, how many users verify phone, etc. Also feed key events into a dashboard for product KPI tracking.


Over time, use these events for advanced features: e.g., trigger a LaunchDarkly flag or in-app message when profile_score_updated indicates a user reached 100%. Because Snowplow is real-time, we could theoretically integrate such triggers with minimal lag (or use its real-time stream to our Node backend).


If Parker decides it needs to send data to many external tools quickly (say marketing wants events in Google Analytics, or support wants data in Intercom), we could hybridize: Use Snowplow to warehouse and maybe use Segment’s HTTP API in parallel for specific events to specific endpoints. But maintaining one source of truth (the warehouse) via Snowplow ensures we have confidence in our data for audits and internal use.


By following these recommendations, Parker will adopt robust, scalable solutions that align with modern architectures: a controlled and reversible rollout process (feature flags), a clean API evolution path, proper lifecycle management of external resources (Stripe), secure and fast verification flows, and a powerful analytics foundation. All these come together to support a responsive, secure, and insight-driven user profile system.
UX Wireframe Kit – Profile & Settings Redesign
(The following section outlines a low-fidelity wireframe plan for Parker’s new Profile system UI, spanning Account details, Traveler info, Notifications, Wallet, and Security. These are structured as tabs in the profile section. Annotations describe key elements and interactions.)
Overall Layout: The Profile will be presented as a tabbed interface (either top tabs on web or a side menu, and a bottom nav on mobile if applicable). The five main sections (tabs) are: Account, Travelers, Notifications, Wallet, Security. This allows users to quickly navigate sub-sections of their profile without scrolling through one long page.
Account Tab: This is the default view showing personal account information. It includes basic info like Name, Email, Phone (with verification status indicator). For example, it might show:


Profile Photo (circle avatar) – with an “Edit” icon overlay to upload a picture.


Name – Jane Doe (text field, editable inline or via an Edit button).


Email – jane@example.com (verified status if email verification in system, if not, at least display).


Phone – +1 234 567 8900 – if not verified, a “Verify” button is shown next to it (or a red label “Unverified”). If verified, a green check icon and text “Verified” are displayed.


Password & 2FA settings might also be linked from here unless we put them fully under Security.


Account Actions – such as “Delete Account” or “Download My Data” (GDPR compliance) could be here or under Security.


Progress Indicator – At the top of Account tab, we could show a profile completeness bar – e.g., “Profile 70% Complete” with a horizontal bar or ring. Under it, a callout: “Add your passport and a secondary contact to complete your profile and unlock faster booking.” This gamifies the account tab. (We will calculate completeness based on fields filled, as Parker’s profile_score does).


Annotation: Account Tab [Screenshot] – Shows profile avatar and basic fields with an edit link for each. A progress bar indicating profile completeness (e.g., a circular progress donut at 70% with text). If some important fields are missing, perhaps a subtle alert box: “Complete your profile to make booking quicker – 3 items left” which when clicked jumps to Travelers tab or opens a checklist modal.


Travelers Tab: This is the multi-traveler management UI. It lists the Saved Travelers associated with the account. For example:


A list with cards or rows:


Jane Doe (Self) – listing key info like DOB, Passport ending ****1234, Known Traveler #: HX8933.


John Doe – relationship: Spouse (if we allow labeling). Key info snippet.


Junior Doe – Child – maybe with a smaller icon indicating minor.


Each entry has an Edit option (pencil icon) and maybe Delete (trash icon) for companions (for the primary self profile, delete may be disabled).


At the bottom or top, an “Add Traveler” button (with a + icon). Clicking it opens a form to input new traveler details (Name, DOB, Gender, Passport No & expiry, Nationality, etc., similar fields to the primary profile).


The UI for editing/adding traveler might be a modal or separate page – but since this is wireframe, likely a modal for quick inline editing. It can reuse components from Account tab (the form fields).


If a traveler has missing info required for international flights (like passport), we might show a small alert icon next to their name.


Annotation: Travelers Tab Wireframe: – possibly includes a note: “Saved travelers can be quickly added to your bookings. Add family or people you frequently book for.” Each traveler card could have an avatar (maybe just initials if no photo for them), their name, and perhaps icons indicating what info is on file (passport icon if passport added, phone icon if contact info present, etc.).

 Interaction: If user tries to delete a traveler that’s linked to a future booking, we should warn them. This requires backend checks. But UI-wise, assume deletion simply prompts “Are you sure?” because data removal.


Notifications Tab: A preferences center for all notification types. The design will likely have categories with toggles, and possibly channel checkboxes:


Possibly use a settings list layout: each category (like Booking Confirmations, Flight Reminders, Price Alerts, Marketing Offers) is a section. Under each, show sub-options or toggles for channels. For example:


Booking Confirmations – [Email ☑️] [SMS ☑️] [Push ☑️] (the user can tick which channels they want for that category) – if we only have email/SMS now, just two toggles are shown. If push/in-app present, include them.


Flight Status Updates – [Email ☑️] [SMS ☑️] [Push ☑️].


Price Drop Alerts – [Email ☑️] [Push ☑️] [SMS ☐] (maybe user turned off SMS for this).


News & Promotions – [Email ☑️] [SMS ☐] [Push ☐]. Possibly separate “Marketing” category.


Below or above, global settings:


Quiet Hours – e.g., a UI element to pick a Do Not Disturb interval. Could be a time picker for “Don’t send notifications between : and :”. If set, we display the range and allow edit. (This could open a sub-modal with from/to selectors and timezone if needed).


Digest Frequency – either a single choice for all or per category. Perhaps a global “Marketing emails frequency: [Immediately / Daily summary / Weekly summary]”. Or a note under Price Alerts “( ) send instantly ( ) daily digest”. This might be too granular for wireframe, maybe start with global digest for non-critical notifs.


Device Notifications – if user has a mobile app linked or web push, might show a status “Push notifications: Enabled on 1 device (iPhone)” with ability to manage devices (this could be advanced, might skip for now).


Each setting likely has a brief description. E.g., “Flight Reminders – e.g., check-in reminders, gate changes”.


At bottom maybe a link “Unsubscribe from all marketing emails” for legal compliance (which essentially toggles off the marketing category).


Annotation: Notifications Tab Example: – mimic Slack’s preferences UI where categories have checkboxes and quiet hours are a separate section. Possibly illustrate a toggle for quiet hours (on/off), and when on, shows the times. The wireframe can highlight the multi-channel matrix clearly.

 Ensure form is accessible: proper labels (we might label checkboxes with the category-channel combination, or use ARIA grouping). On mobile, a simpler stack might be better (each category -> opens an accordion of channels).


Wallet Tab: The payment methods UI. This will list saved payment methods and allow add/remove. For example:


A list of cards on file: show brand logo (Visa/Mastercard etc.), last 4 digits, and exp date. Possibly also a label/nickname if user can set (or at least “Personal Card” vs “Corporate Card” if we allow).


Each card entry has maybe a “Delete” (or “Remove”) button. Possibly an “Edit” if we allow updating billing address or so – but often one would just remove and re-add.


One card could be marked as Default (for auto-charging if needed). Could indicate with a star icon and text “Default”. Clicking another card’s “Make Default” would switch it.


Add Payment Method button: clicking opens a form or Stripe Elements modal. Likely we’ll integrate Stripe’s card input (we can use Stripe.js to provide a secure card entry form). The UI might just show a button “Add Card” that triggers the Stripe card collection modal. For wireframe, we note that pressing Add triggers the SetupIntent process (user enters card, maybe with name and billing ZIP).


If Parker uses Stripe’s new Payment Request (Apple Pay/Google Pay) integration, we could also show those options in add flow.


Also consider showing PayPal or other wallets if planned. For now, assume credit/debit cards via Stripe.


Security note text: perhaps at bottom, small font: “Your payment methods are securely stored by our payment processor (Stripe). We do not keep full card numbers.” This reassurance can be included in the UI to build trust.


Annotation: Wallet Tab Layout: – maybe an image of a generic card icon with last4. The “Remove” button likely a trash can icon. If multiple cards, stack them with slight card graphic (like Apple Wallet style) or simple list. The Add button could be a plus icon “Add Payment Method”. We might incorporate a progress ring if wallet is not set up at all, e.g., if no card, show a message “You have no payment methods saved. Add one to enable one-click bookings.” possibly with a prompt arrow.

 When user removes a card, confirmation is needed (prevent accidental removal). After removal, we’ll call detach on backend as per plan, but user just sees it disappear from list.


Security Tab: Focused on account security settings:


Password: Show last updated date, and a “Change Password” button. If using passwordless/Social, this might differ; assuming we have password login, this opens a modal to enter current and new password.


Two-Factor Authentication (2FA): If Parker implements 2FA (perhaps via Authenticator app or SMS 2FA for login), show status: e.g., “Two-step verification: Enabled (Authenticator App)” or “Disabled”. Provide button “Enable 2FA” which walks user through setup (could be via TOTP QR code etc.). If 2FA is on, allow disable or regenerate backup codes. This is forward-looking if not present now.


Authorized Devices / Sessions: Some apps list logged-in devices or sessions so user can revoke them. We might include a list like “Active Sessions: Web session (Chrome on Windows, logged in 2 days ago) – [Log out]”. This adds security transparency. If not feasible immediately, can skip, but it's good practice especially if we allow multiple device logins.


Security Alerts: toggle “Notify me of new logins or unusual activity” – some users want an email if a new device logs in. Could be a checkbox.


Possibly tie in Identity Verification (KYC) status if relevant: e.g., Stripe Identity verification – Parker has optional KYC via Stripe Identity. If user has done it, show “Identity Verified: Yes (ID: Driving License verified on 2024-01-10)”. If not, maybe a prompt “Verify your identity to increase purchase limits and speed up bookings – [Verify Now]”. This could be under Security or Account – likely Security because it’s sensitive info.


Account Deletion: sometimes put here. A button “Delete Account” (with confirm flow) might reside in security or account settings. It’s a critical action, but often security page houses it (as a last resort action with warnings about data removal).


Annotation: Security Tab Highlights: – Partition sections for Password, 2FA, Devices. E.g., show a padlock icon next to fields. For wireframe clarity, perhaps depict a toggle for 2FA with explanatory text: “Require a code from my phone on login.” If user clicks enable, we then show QR code etc. (not in wireframe, but design for it).

 Also consider social login linking if applicable: e.g., if user signed up via Google, security tab might show “Connected Accounts: Google (connected) [Disconnect]”. If none, maybe allow linking a social for login ease.


This tabbed profile structure ensures all related settings are discoverable yet separated for clarity. The design should maintain consistency with Parker’s branding (colors, typography) and remain responsive (e.g., on mobile it might become a swipe-able tab view or an accordion of sections). Below is a summary wireframe mapping (in text form due to medium):
Profile Main Screen (Desktop view): Top header “Your Profile” with perhaps a subtitle or breadcrumb. Underneath, a horizontal tab menu:


Account | Travelers | Notifications | Wallet | Security (active tab highlighted).


Account (active): [Profile avatar]
 Name: Jane Doe (Edit)
 Email: jane@example.com (Edit)
 Phone: +1 234 567 8900 (Verified ✅ / Verify link if not)
 Profile Completion: 70% – “Complete additional details to reach 100%.” (maybe a progress bar here)
 (List of missing items if any, like a mini checklist: e.g., “– Add passport info”, “– Verify phone number” if those are not done. Each could link to relevant tab.)

 Travelers: [list of traveler cards with Add button]
 (If none besides self: prompt “Add a traveler profile for someone you book trips for.”)

 Notifications:


Booking Updates: Email ☑️ SMS ☑️ Push ☑️


Flight Reminders: Email ☑️ SMS ☑️ Push ☑️


Price Alerts: Email ☐ SMS ☐ Push ☑️ (example where user opted only for push)


Marketing Offers: Email ☑️ SMS ☐ Push ☐
 Quiet Hours: Enabled (Do not disturb 22:00–07:00) (Edit)
 Digest Setting: Weekly digest for price alerts (Edit)
 (plus any explanatory notes)


Wallet:


Visa ****1234 exp 09/25 (Default) – Remove


Mastercard ****9876 exp 01/24 – Remove / Make Default


Add Payment Method
 (Note: Parker does not store full card data; managed by Stripe.)


Security:


Password: Last changed 3 months ago. [Change Password]


Two-Factor Authentication: Disabled. [Enable 2FA] (Recommended)


Active Sessions: 2 devices – [View Devices] (which might pop up a list with logout options)


Identity Verification: Not Verified. [Verify ID] (if Parker uses KYC)


Account: [Delete Account] (danger zone, perhaps a red button)


The above is conveyed in a low-fi way – in implementation, we’d style these nicely (e.g., cards or grouped lists). The key is the structure and the new elements (progress bars, toggles, multi-traveler management UI, etc.) that were not in Parker’s original UI. Each item we add also ties back to the earlier research: e.g., profile completeness bar (Track A), travelers (Track C), notification granularity (Track C), etc.
By deploying this redesigned interface, Parker will significantly improve usability and clarity. Users can self-service many things (update info, manage family travelers, control notifications, see security status) that currently might require support or aren’t possible. This drives engagement and trust: the user feels in control of their profile. We’ve also laid it out to be consistent and modern, akin to how leading apps present settings (many follow a similar tab or segmented pattern for profile vs security vs notifications).
Sprint-ready Task List (S-1 to S-5)
Below is a proposed breakdown of implementation tasks over the next 5 sprints (assuming 1-2 week sprints). Each task is phrased as a user story or technical story, with acceptance criteria and an estimated point score. (We assume an agile process with story points, e.g., 1 = trivial, 2 = small, 3 = medium, 5 = large, 8 = very large.)
Sprint 1: Foundations & Quick Wins
S-1: Profile Completion Indicator & Tracking – Implement profile completeness calculation and UI display.
 Acceptance Criteria: A profile_completeness_score is computed for each user (e.g., as a percentage of key fields filled). This is displayed on the Account tab as a progress bar or ring. If score <100%, show the next suggested action (e.g., “Please add ___”). Updating any profile info should recalc the score in real-time (or on page refresh). The score update event is emitted to analytics as profile_score_updated with old/new values.
 Points: 5 – Moderate. (Requires backend calculation, minor schema change if storing score, frontend UI work, and analytics integration.)


S-2: Multi-Traveler Profile Management – Enable adding and editing multiple traveler profiles per user.
 Acceptance Criteria: In the UI, there is a Travelers tab listing all traveler profiles associated with the user. User can add a new traveler: opens a form with required fields (Name, DOB, Gender, Passport, etc.), validation on each. Upon save, the traveler appears in the list and is persisted in the database (new traveler_profiles row linked to user). User can edit or delete a companion profile (except their own primary profile). Deletion asks for confirmation and then removes the DB entry. RLS ensures one user cannot access another’s travelers.
 Points: 8 – Large. (New UI, form, multiple backend endpoints: create, update, delete traveler profiles, plus testing.)


S-3: Twilio Verification Webhook & Profile Flag – Integrate Twilio Verify Events for phone verification and reflect status in profile.
 Acceptance Criteria: Twilio’s webhook for verification events is configured to hit our endpoint (e.g., /twilio/verifyWebhook). The Edge Function validates the request (using Twilio signature) and on a verification.approved event, it sets the user’s phone_verified=true in the DB (if not already). Failure or max-attempt events can be logged for analysis. On the frontend, after user enters the code (client callback), the phone verification status updates immediately as before. Additionally, if a webhook comes in, it will ensure consistency (even if user closed the app mid-process). We consider it passed if manual testing shows that verifying via code triggers the success state, and the webhook endpoint receives Twilio calls (simulate via Twilio console).
 Points: 3 – Small-medium. (Mostly backend logic and config, minimal UI impact besides maybe showing a loading state until confirmed.)


S-4: Feature Flag Integration (LaunchDarkly) – Set up LaunchDarkly and gate the new profile features.
 Acceptance Criteria: LaunchDarkly client is integrated. There is a feature flag new_profile_ui which, when off, the app will show the old profile page (if we still have one) and when on, shows the new tabbed profile interface. (Alternatively, flag specific subsections like multi_traveler or profile_completion if we want granular control.) For acceptance, demonstrate that toggling the flag in LD changes the behavior in real-time for a test user. Also, ensure unauthenticated contexts or default have flag off (so we can control rollout). Team members are targeted to “on” in LD for development testing.
 Points: 5 – Moderate. (Setting up LD, wiring flag usage in code, testing multiple scenarios.)


S-5: Stripe Card Detach on Removal – Ensure payment method deletions propagate to Stripe.
 Acceptance Criteria: When a user deletes a saved payment method in the Wallet tab, the system calls stripe.paymentMethods.detach for that payment’s Stripe ID. After deletion, the card no longer appears in Parker UI and is confirmed detached via Stripe dashboard or API (for testing, list the customer’s payment methods – it should be gone). If Stripe call fails, an error is logged and the UI shows a generic error (or tries again). No orphan card tokens remain associated with the user’s Stripe customer. Also, document in code comments that we intentionally detach for security.
 Points: 3 – Small. (One backend function update and tests.)


Sprint 2: Enhancements & Compliance
S-1: Notification Preferences Expansion – Revamp Notifications tab to include channel-specific toggles, quiet hours, and digest settings.
 Acceptance Criteria: The Notifications settings page now lists each notification category with separate toggles for Email, SMS (and Push, if applicable). Changes are saved to notification_preferences JSON in the DB. Quiet Hours can be set: user can input a start and end time; those are stored (e.g., in profiles table or separate settings table). Digest frequency can be chosen for at least one category (e.g., price alerts: instant vs daily). For acceptance, verify that toggling any combination properly updates the DB and that a user’s choices persist (reload page to see them). Also, update the notification sending logic to respect these: simulate a notification event and show that if within quiet hours or channel off, the notification is suppressed or queued (can be a unit test or log output proving the check).
 Points: 8 – Large. (Significant UI work, plus some backend logic to enforce quiet hours in our send functions.)


S-2: Accessibility Audit Fixes (Profile Pages) – Address WCAG 2.1/2.2 issues in the new profile UI.
 Acceptance Criteria: Conduct an accessibility audit using axe or similar on the profile pages and fix all identified issues of severity serious or higher. Specifically: all form fields have associated <label> or aria-label (e.g., traveler form inputs), color contrast for text and focus indicators meets AA (adjust CSS if needed to ensure 4.5:1 contrast, and ensure focus outline thickness per WCAG 2.2 guidelines). The tab interface is navigable via keyboard (arrow keys or Tab as appropriate) and has aria-selected on active tab etc. Any new interactive element (toggles, buttons) is accessible (e.g., use <button> for toggles or add role="switch" and proper states). For “Redundant Entry”, ensure that if a user’s personal info is known, we reuse it (e.g., when adding self as traveler, prefill from Account info). We will consider this done when all pages can be fully used via keyboard only and screen reader reads all important info (test with NVDA or VoiceOver). Also test an RTL locale (just swap in a test translation to Arabic) to confirm layout doesn’t break drastically – though full RTL support might be Sprint 3 if issues.
 Points: 5 – Moderate. (Fixes may vary but likely medium effort to add labels, tweak styles, test.)


S-3: Delete Account (GDPR compliance) – Implement user account deletion with data cleanup.
 Acceptance Criteria: A user can request account deletion from the Security tab. After confirming (e.g., re-enter password or type DELETE), the system will deactivate their account. This includes: removing personal data from profiles (or anonymizing if we prefer), deleting related traveler_profiles, notification prefs, and crucially, calling Stripe to delete the customer if exists and no chargessnowplow.io, and removing Twilio verified phone record if any (Twilio Verify doesn’t store PII long-term, but ensure no active verifications). The account row in auth (Supabase) can either be removed or marked (Supabase Auth requires a deletion via its API). Acceptance is that after deletion, the user can no longer log in, their data is not accessible, and Stripe dashboard confirms customer gone if criteria met. Also, verify that if user had past transactions, we do not delete those records (we may keep some data for legal). Possibly implement as a “GDPR delete” function that scrubs personal fields (name, email replaced with random) rather than full row delete, depending on compliance strategy – but given small scope, a full delete is fine.
 Points: 5 – Moderate. (Involves backend orchestration of deletes across services, and thorough testing to avoid partial deletion issues.)


S-4: Snowplow Analytics Integration – Start capturing profile-related events via Snowplow.
 Acceptance Criteria: Snowplow tracker is added and configured on the frontend. When a user updates their profile or completes a key action, events are sent to Snowplow. Specifically implement at least: profile_created, profile_score_updated (with the schema as defined), traveler_added, and notification_pref_updated events. Set up a basic Snowplow collector (could be a test endpoint or Snowplow Mini instance) and demonstrate events arriving with correct schema. For acceptance, show an example event in the warehouse (or collector log) with all expected properties. Also ensure no PII is in events that shouldn’t be (we can include user_id as a pseudonymous key but avoid raw email, etc., in event payload). This story is done when events are flowing and we have a way to verify data (perhaps a small admin panel listing last N events, or simply via Snowplow’s own monitoring).
 Points: 5 – Moderate. (Initial setup and instrumentation of a few events.)


S-5: LaunchDarkly Rollout of New Profile (50% → 100%) – Gradually enable the new profile system for all users.
 Acceptance Criteria: Using the LaunchDarkly flag new_profile_ui, perform a staged rollout: ramp from internal-only to 50% to 100% of users over this sprint (or simulate it). Ensure that during rollout, no errors are reported from users on old vs new UI (we need to maintain both until fully launched). By sprint’s end, the flag is 100% on for all users, effectively making the new profile permanent. Acceptance means support team has not received negative feedback during 50% phase, and metrics like profile completion or error rates remain good. Once at 100%, we clean up any legacy code (if any) related to old profile page.
 Points: 3 – Small. (Mostly configuration and monitoring; the heavy work was integrating LD and building the feature – which we did in Sprint 1. This is executing the rollout plan.)


Sprint 3: Refinements & Future Prep
 (Likely tasks in Sprint 3 might include further localization efforts, building out 2FA, additional analytics or marketing integrations, etc., but focusing on the scope given:)
S-1: Localization Framework Implementation – Internationalize strings and layout for easy localization.
 Acceptance Criteria: All user-facing text in the profile module (and ideally entire app) is moved to a localization system (e.g., JSON resource files). We introduce at least one alternate language file (e.g., Spanish) to test. Users can switch a language setting (or it’s browser locale-driven) and see the profile UI in that language. Also, verify the layout handles longer text (simulate German, or use pseudo-Latin) without breaking the design. Test an RTL switch (maybe use Arabic for a couple of labels) to see that the tab order and alignment flip properly (this might require adding dir="rtl" attribute and ensuring our CSS uses logical properties). This story is done when we can easily add a new language by supplying translations, and when switching languages, there are no obvious missing texts or misaligned UI.
 Points: 8 – Large. (Retrofitting i18n touches many components, lots of find/replace of strings.)


S-2: Two-Factor Authentication (2FA) Option – Offer and enforce 2FA for account login.
 Acceptance Criteria: Users can enable 2FA in Security tab: on clicking enable, they are shown a QR code (TOTP) and a recovery code. Once set up, next login requires a code from authenticator. Alternatively or additionally, allow SMS-based 2FA via Twilio (since we have phone). For acceptance, demonstrate that a user with 2FA enabled must enter a code after password to successfully login. The Security tab should show 2FA status and allow disable (with proper verification). Also, test that disabling works (and maybe require re-auth for such a critical action). This must integrate with Supabase Auth or our own authentication flow – possible using Supabase’s OTP if available, or a custom implementation storing secret and verifying TOTP.
 Points: 8 – Large. (Security heavy, requires careful QA, and integration with auth system.)


S-3: Group Booking Flow Integration – Utilize traveler profiles in booking checkout.
 Acceptance Criteria: (This is more of a product integration task.) In the flight booking UI, when the user is filling traveler info, they can select from their saved Travelers. For acceptance, on the passenger info page, if user has 3 saved travelers, they can choose each from a dropdown and the fields auto-fill. They can also add a new traveler on the fly (which offers to save to profile). Bookings created will reference the traveler_profile IDs internally if possible. Essentially, ensure the multi-traveler profiles we built are actually leveraged in the booking experience. Acceptance: test a multi-passenger booking where 2 are chosen from saved list and 1 is new – the saved ones should not require typing details, and after booking, that new person is offered to save to profile.
 Points: 5 – Moderate. (Needs coordination with booking logic, but mostly UI/UX glue.)


S-4: Privacy & Consent Compliance – Refine consent flows for communication and data usage.
 Acceptance Criteria: Ensure we have explicit user consent for marketing communications (e.g., a checkbox at signup or in profile that they can opt in/out – likely the marketing toggle suffices as consent record). Also implement a “Cookie/Tracking consent” banner if not already, to comply with EU laws if we use any cookies for analytics. Additionally, add a section in Security or Account: “Data & Privacy” linking to privacy policy and allow user to request data export (if we can implement an export function easily, else at least tell them contact support). Acceptance if legal review (hypothetical) is satisfied that user has control to opt out of comms and can delete account (we did), and is informed about data practices. This is more of a non-functional requirement, but crucial. Possibly verify that Segment/Snowplow does not run without consent for EU users (we might decide Snowplow events for essential features are legitimate interest, but marketing events require opt-in – to be configured accordingly).
 Points: 3 – Small-medium. (Mostly adding UI text/checkbox and adjusting settings, low dev complexity but important.)


S-5: Performance & Load Testing (Profile Services) – Ensure the new profile system scales to 100k+ users as planned.
 Acceptance Criteria: Simulate high load on the profile endpoints and measure response times. For example, use a script or service to perform 100 requests per second to secure-traveler-profiles (reading or writing) and ensure response < 200ms on average. Also test database load of computing profile scores or retrieving multiple travelers. Identify any slow queries (add indices or optimize queries if needed, e.g., ensure index on user_id in traveler_profiles). Also test front-end performance: the profile page should load quickly even with, say, 10 saved travelers and a dozen toggles – ensure no noticeable lag (use Lighthouse performance score as a metric, aim >90 for the profile page). Acceptance: Document results of load test and any fixes done (like caching or N+1 query elimination). Parker’s goal of sub-2s response for profile ops should be met even under heavy usage.
 Points: 5 – Moderate. (Setting up tests and possibly optimizing code.)


Each sprint’s tasks collectively address key priorities in sequence: first getting the new features in place (Sprint 1), then expanding and hardening them (Sprint 2 with accessibility, preferences, analytics, deletion), then future-proofing more (Sprint 3 with i18n, 2FA, deeper integration). This sequencing can be adjusted based on team velocity and any external deadlines (e.g., perhaps accessibility fixes might be bumped earlier if a compliance audit looms).
Note: Story point estimates assume a 2-weeks sprint with a small dev team – adjust as needed. Also, some tasks might overlap or require earlier start (for example, starting i18n earlier might be wise), but they are listed where they fit logically after foundational pieces are done.

By following these detailed recommendations and implementation steps, Parker Flight will evolve its User & Traveler Profile system into a state-of-the-art solution. The new profile experience will be engaging and user-friendly (Track A outcomes), the engineering will be scalable, maintainable, and secure (Track B), and the system will be ready for the future – supporting more users, more use-cases (like families and groups), and meeting regulatory standards in accessibility and privacy (Track C). Each improvement is backed by contemporary best practices and references from industry leaders, ensuring Parker remains competitive and compliant as it grows.

